{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+zRgOHQgTuxd7jxUzOL+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bca3f0a00fb4102a4bf6a6df44444a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcc7f945ffc940f4bccbc7c92297396e",
              "IPY_MODEL_9a5588579d2944ceb75908b89191cd9c",
              "IPY_MODEL_212d7d17414f4cb0a9a468ca0967f871"
            ],
            "layout": "IPY_MODEL_19a1d1acd12343a3894816e8e9d86d04"
          }
        },
        "fcc7f945ffc940f4bccbc7c92297396e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d4eea8771a64a66974e7f49d2e267bf",
            "placeholder": "​",
            "style": "IPY_MODEL_34324354171242d0bb0daca00fe04fde",
            "value": "yolox_l0.05.onnx: 100%"
          }
        },
        "9a5588579d2944ceb75908b89191cd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af57be713c34e1e9ec3100d7028d50b",
            "max": 216625723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96eff2a9f8a1451ba53df1986d5c9ee1",
            "value": 216625723
          }
        },
        "212d7d17414f4cb0a9a468ca0967f871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4195e928664880b25018974b03369a",
            "placeholder": "​",
            "style": "IPY_MODEL_876fdf288db54b11816a3d9eb1c38d8d",
            "value": " 217M/217M [00:01&lt;00:00, 140MB/s]"
          }
        },
        "19a1d1acd12343a3894816e8e9d86d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4eea8771a64a66974e7f49d2e267bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34324354171242d0bb0daca00fe04fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8af57be713c34e1e9ec3100d7028d50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96eff2a9f8a1451ba53df1986d5c9ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c4195e928664880b25018974b03369a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876fdf288db54b11816a3d9eb1c38d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarthakpunj/Text-extractor-from-pdf/blob/main/Untitled43.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZZUbviFQRwwH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting text from images"
      ],
      "metadata": {
        "id": "mv17-JDKRn2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"ustructured[all-docs]\" pillow pydantic lxml matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa2t-kmAOBb9",
        "outputId": "9fd3f20c-4acf-4896-9568-c907e4756f99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ustructured[all-docs] (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ustructured[all-docs]\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoDt8KRaR7Nm",
        "outputId": "6e67d8db-d8ff-4fe1-bbf9-6b9b3db57fc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,765 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,017 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,742 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Fetched 23.0 MB in 4s (5,924 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get intall poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzD8KbW9SVbL",
        "outputId": "bd0d6879-3228-4625-cf6d-fd521ae28ea0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Invalid operation intall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libleptonica-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMvL6672Saiy",
        "outputId": "666af745-0ae0-429d-a1aa-aac46c7c6d96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "tesseract-ocr-eng set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libimagequant0 libraqm0 python3-olefile\n",
            "Suggested packages:\n",
            "  python-pil-doc\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libimagequant0 libleptonica-dev libraqm0 libtesseract-dev\n",
            "  python3-olefile python3-pil tesseract-ocr-script-latn\n",
            "0 upgraded, 8 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 35.1 MB of archives.\n",
            "After this operation, 107 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.4 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libimagequant0 amd64 2.17.0-1 [34.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libraqm0 amd64 0.7.0-4ubuntu1 [11.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-olefile all 0.46-3 [33.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-pil amd64 9.0.1-1ubuntu0.3 [419 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-script-latn all 1:4.00~git30-7274cfa-1.1 [30.9 MB]\n",
            "Fetched 35.1 MB in 3s (10.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../1-libimagequant0_2.17.0-1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.17.0-1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../2-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libraqm0:amd64.\n",
            "Preparing to unpack .../3-libraqm0_0.7.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libraqm0:amd64 (0.7.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../4-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../5-python3-olefile_0.46-3_all.deb ...\n",
            "Unpacking python3-olefile (0.46-3) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../6-python3-pil_9.0.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (9.0.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package tesseract-ocr-script-latn.\n",
            "Preparing to unpack .../7-tesseract-ocr-script-latn_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-script-latn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-script-latn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up python3-olefile (0.46-3) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libraqm0:amd64 (0.7.0-4ubuntu1) ...\n",
            "Setting up libimagequant0:amd64 (2.17.0-1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up python3-pil:amd64 (9.0.1-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured-pytesseract\n",
        "!pip install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4BHhON1SjRX",
        "outputId": "d36ca04f-7333-4a77-a7db-9588d3f9cc30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured-pytesseract\n",
            "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from unstructured-pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-pytesseract) (11.2.1)\n",
            "Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: unstructured-pytesseract\n",
            "Successfully installed unstructured-pytesseract-0.3.15\n",
            "Collecting tesseract-ocr\n",
            "  Downloading tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from tesseract-ocr) (3.0.12)\n",
            "Building wheels for collected packages: tesseract-ocr\n",
            "  Building wheel for tesseract-ocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract-ocr: filename=tesseract_ocr-0.0.1-cp311-cp311-linux_x86_64.whl size=179092 sha256=367263eca06240ae38693a015936eb45271c795a1ac4911503899b80c01e064f\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/83/3c/d2b68d844d169d6015fc2ad8c93207d778829c87e26c6f2206\n",
            "Successfully built tesseract-ocr\n",
            "Installing collected packages: tesseract-ocr\n",
            "Successfully installed tesseract-ocr-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the unstructured library with necessary extras\n",
        "!pip install \"unstructured[all-docs]\" pillow pydantic lxml matplotlib\n",
        "\n",
        "# Update apt-get\n",
        "!sudo apt-get update\n",
        "\n",
        "# Install poppler-utils for PDF handling\n",
        "!sudo apt-get install poppler-utils\n",
        "\n",
        "# Install tesseract and related libraries for OCR\n",
        "!sudo apt-get install libleptonica-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn\n",
        "\n",
        "# Install unstructured-pytesseract and tesseract-ocr (though the previous apt-get should cover tesseract)\n",
        "!pip install unstructured-pytesseract\n",
        "!pip install tesseract-ocr\n",
        "\n",
        "# Import the necessary function\n",
        "from unstructured.partition.pdf import partition_pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CpZ_gsfLTUQ6",
        "outputId": "3d10e61f-4f0d-48ae-b8ea-7d8ff064ee66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting unstructured[all-docs]\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (5.2.0)\n",
            "Collecting filetype (from unstructured[all-docs])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured[all-docs])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (4.13.4)\n",
            "Collecting emoji (from unstructured[all-docs])\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured[all-docs])\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured[all-docs])\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured[all-docs])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.0.2)\n",
            "Collecting rapidfuzz (from unstructured[all-docs])\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured[all-docs])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (4.14.0)\n",
            "Collecting unstructured-client (from unstructured[all-docs])\n",
            "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured[all-docs])\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (1.1)\n",
            "Collecting onnxruntime>=1.19.0 (from unstructured[all-docs])\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting python-pptx>=1.0.1 (from unstructured[all-docs])\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting effdet (from unstructured[all-docs])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting pypandoc (from unstructured[all-docs])\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pikepdf (from unstructured[all-docs])\n",
            "  Downloading pikepdf-9.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting google-cloud-vision (from unstructured[all-docs])\n",
            "  Downloading google_cloud_vision-3.10.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (0.3.15)\n",
            "Collecting pdfminer.six (from unstructured[all-docs])\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting unstructured-inference>=0.8.10 (from unstructured[all-docs])\n",
            "  Downloading unstructured_inference-1.0.5-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.0.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (2.2.2)\n",
            "Collecting pdf2image (from unstructured[all-docs])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.1.5)\n",
            "Collecting python-docx>=1.1.2 (from unstructured[all-docs])\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pypdf (from unstructured[all-docs])\n",
            "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting onnx>=1.17.0 (from unstructured[all-docs])\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]) (3.8)\n",
            "Collecting pi-heif (from unstructured[all-docs])\n",
            "  Downloading pi_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.17.0->unstructured[all-docs]) (5.29.5)\n",
            "Collecting coloredlogs (from onnxruntime>=1.19.0->unstructured[all-docs])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx>=1.0.1->unstructured[all-docs])\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (0.0.20)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (0.32.4)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (2.6.0+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (1.0.15)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (4.52.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (1.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.10->unstructured[all-docs]) (1.15.3)\n",
            "Collecting pypdfium2 (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured[all-docs]) (2.7)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured[all-docs])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (0.21.0+cu124)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (2.0.9)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.25.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]) (1.26.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[all-docs]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all-docs]) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all-docs]) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all-docs]) (2024.11.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->unstructured[all-docs]) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[all-docs]) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[all-docs]) (43.0.3)\n",
            "Collecting Deprecated (from pikepdf->unstructured[all-docs])\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: olefile in /usr/lib/python3/dist-packages (from python-oxmsg->unstructured[all-docs]) (0.46)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[all-docs]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[all-docs]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[all-docs]) (2025.4.26)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]) (24.1.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]) (1.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (0.16.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->unstructured-inference>=0.8.10->unstructured[all-docs]) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.19.0->unstructured[all-docs]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs]) (0.21.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->unstructured-inference>=0.8.10->unstructured[all-docs]) (1.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs])\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->unstructured-inference>=0.8.10->unstructured[all-docs]) (3.0.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_inference-1.0.5-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_cloud_vision-3.10.1-py3-none-any.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.36.0-py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=1c58ca160d48ee62d7b8a0dfb06cd09c3ee55afd53eeb64b700128f081316d1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, XlsxWriter, rapidfuzz, python-oxmsg, python-magic, python-iso639, python-docx, pypdfium2, pypdf, pypandoc, pi-heif, pdf2image, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, langdetect, humanfriendly, emoji, Deprecated, backoff, typing-inspect, python-pptx, pikepdf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, unstructured-client, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, dataclasses-json, unstructured, google-cloud-vision, unstructured-inference, effdet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Deprecated-1.2.18 XlsxWriter-3.2.3 backoff-2.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 effdet-0.4.1 emoji-2.14.1 filetype-1.2.0 google-cloud-vision-3.10.1 humanfriendly-10.0 langdetect-1.0.9 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 onnxruntime-1.22.0 pdf2image-1.17.0 pdfminer.six-20250506 pi-heif-0.22.0 pikepdf-9.8.1 pypandoc-1.15 pypdf-5.6.0 pypdfium2-4.30.1 python-docx-1.1.2 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 python-pptx-1.0.2 rapidfuzz-3.13.0 typing-inspect-0.9.0 unstructured-0.17.2 unstructured-client-0.36.0 unstructured-inference-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "61c5e5d68fc84faaabc3477c8e24ecdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 1s (213 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126381 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libleptonica-dev is already the newest version (1.82.0-3build1).\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "tesseract-ocr-script-latn is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "python3-pil is already the newest version (9.0.1-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Requirement already satisfied: unstructured-pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from unstructured-pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-pytesseract) (11.2.1)\n",
            "Requirement already satisfied: tesseract-ocr in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from tesseract-ocr) (3.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_element=partition_pdf(#extracts elements from pdf\n",
        "    filename=\"/content/data/BCSE497J Project I Report - Template FINAL Updated  (1).pdf\",\n",
        "    strategy=\"hi_res\",\n",
        "    extract_images_in_pdf=True,\n",
        "    extract_image_block_types=[\"Image\",\"Table\"],\n",
        "    extract_image_block_to_payload=False,\n",
        "    extract_image_block_output_dir=\"extracted_data\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0bca3f0a00fb4102a4bf6a6df44444a3",
            "fcc7f945ffc940f4bccbc7c92297396e",
            "9a5588579d2944ceb75908b89191cd9c",
            "212d7d17414f4cb0a9a468ca0967f871",
            "19a1d1acd12343a3894816e8e9d86d04",
            "8d4eea8771a64a66974e7f49d2e267bf",
            "34324354171242d0bb0daca00fe04fde",
            "8af57be713c34e1e9ec3100d7028d50b",
            "96eff2a9f8a1451ba53df1986d5c9ee1",
            "2c4195e928664880b25018974b03369a",
            "876fdf288db54b11816a3d9eb1c38d8d"
          ]
        },
        "id": "9fuCIBlrULul",
        "outputId": "70ca1e9e-8a4d-4382-cd22-5c114ec7e91e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "yolox_l0.05.onnx:   0%|          | 0.00/217M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bca3f0a00fb4102a4bf6a6df44444a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3pr4-EbZ5rM",
        "outputId": "dc91c26a-c1e6-4851-84f5-b79da0a4d9c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Title at 0x7884bf508350>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf64c190>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf64d9d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a628d810>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf57d510>,\n",
              " <unstructured.documents.elements.Title at 0x7884a628cb10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf57ef90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a628cfd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf811e10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf813690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8132d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf813650>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf810590>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf812610>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf57e290>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf64f890>,\n",
              " <unstructured.documents.elements.Image at 0x7884a628cf90>,\n",
              " <unstructured.documents.elements.Title at 0x7885bb20f350>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf59ebd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf812990>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf666250>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b89910>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b88e10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b8bd90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf989410>,\n",
              " <unstructured.documents.elements.Title at 0x7884a62a4710>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6d7850>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf811c90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6d4050>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7b4b50>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf57e990>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf431e10>,\n",
              " <unstructured.documents.elements.Text at 0x7884a628fc10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf6cc710>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf6954d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884a628d790>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf694ad0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6d4b50>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f7d50>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3f6ed0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf40e350>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f4610>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3f45d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f4ad0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f4d90>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f44d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f7550>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3f6e10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf3f5c10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf40ea50>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6974d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf37b2d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf378710>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf3d9790>,\n",
              " <unstructured.documents.elements.Title at 0x7884a62447d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf378850>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3dbdd0>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf40d1d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a628c810>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6fc890>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf40fa50>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf67ed90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6ff110>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6fc090>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6fdd90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6fe710>,\n",
              " <unstructured.documents.elements.Title at 0x7884c21e8350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf67c310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf67c3d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ecdd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3efc90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3f6250>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf67e350>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3ef7d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ec510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dc4d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8df3d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dd190>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8ddd90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8de850>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2623810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8deb90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dd250>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8ddad0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f1dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8de0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8df390>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dc890>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f33d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf8de750>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dc850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dfd90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dd010>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dea50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dee10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dd4d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8df790>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f2c10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8de1d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf8dffd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ee710>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7fb750>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f0450>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7fa890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57f550>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57ead0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57d650>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57f190>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f0ed0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57c710>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57fb50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57c890>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf57dad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57c8d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57edd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57d910>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57c4d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f2350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57c490>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57da50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57f090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57cfd0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f2b50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57fb90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf57f010>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e1f10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e3550>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9f1c10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e1d10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3d8050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf9f1b90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf70ae10>,\n",
              " <unstructured.documents.elements.Text at 0x7884c49a5710>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf70a210>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e7b90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7a6510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7885bb229990>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f44d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f7d10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40fdd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7a62d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6a13d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f58d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7f5f10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7f6bd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f7c10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40e5d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f6d10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f5c90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f4f90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f4050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f4a50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c22185d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7f6550>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c2219c90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55cad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55ec90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55d690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55d610>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40f810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55fb10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55c090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55dbd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55cf50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55f850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55cb10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40cfd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55c910>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf55e910>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d5a10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d7390>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d7450>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d7510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d5210>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d5550>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40da10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf51cf50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d4590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d5850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf62be90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf628fd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf62b590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf629890>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40cbd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6d4e90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf62bb10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629e0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629c690>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40ef50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629c310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629c790>,\n",
              " <unstructured.documents.elements.Title at 0x7884a629e090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629db50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629d190>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629fa90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629e990>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629c590>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c0d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629e290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629e810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629fd90>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40f350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629fcd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629d150>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6a11d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629fad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf35c990>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf57c1d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a629f210>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf35e910>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35f410>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35fc10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35d410>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35f450>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35e8d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35e210>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35dd50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35e510>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35eb90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35d110>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35c050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35cd10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35eed0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35d990>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35ef50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35f950>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35e810>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40d250>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35dad0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35d910>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35cc10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35f650>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35e0d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35c2d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf35ccd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf5ffe50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fdbd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fe390>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40eed0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf35c090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fec50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fd790>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fc350>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40fa10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5fcf90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68b3d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68ad10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68b050>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40f510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68ac90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68af10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf688090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68a8d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40fe90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68be50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68b1d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf689b10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf68aa50>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40e810>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf68b010>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf68acd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a62487d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a624a590>,\n",
              " <unstructured.documents.elements.Title at 0x7884a624aa50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a624ad50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a624a050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a624a4d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6248bd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6248450>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40f7d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf68b690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6248750>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6248050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6249850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6248e90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6249150>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6249a10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a624b350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a624b650>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6249010>,\n",
              " <unstructured.documents.elements.Title at 0x7884c1b41550>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41210>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b43f90>,\n",
              " <unstructured.documents.elements.Title at 0x7884c1b40210>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b40e90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41450>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41850>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b41050>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40dd50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6249cd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6249690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41b10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b407d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b41b90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b40d10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7b4890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7b4790>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7b55d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7b4a50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf7b6210>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf7b7690>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf7b4110>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf674dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf676b50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf677190>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf674890>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf674850>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf675c90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf674610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf646dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf644150>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf644910>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf645610>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c950>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7b6ed0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6751d0>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf674e50>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884c1b41590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf646250>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf730ed0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7308d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf733c10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40d810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b40ad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7329d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6443d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5c8c10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40e590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5cb410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf433e50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf431110>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf432090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf430410>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40f890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf431d50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf432cd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf433810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf433bd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf432410>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40e510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf430f10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf433450>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf432d50>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf433a50>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf518490>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6c75d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6c5a50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c4c90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c5390>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c56d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c57d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c9d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf433350>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf432d10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c4e50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c5450>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c7d10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c4e10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c7010>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c6210>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c7b50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6c4710>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c4250>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6c5f50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf747d10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf747590>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf747190>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf744250>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf7449d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf744dd0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40ca90>,\n",
              " <unstructured.documents.elements.Header at 0x7884bf6c5d10>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf6c6710>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf744e50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf745310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b63290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884c1b619d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b60cd0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c110>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf747510>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b61fd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1b60f50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6ce5d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cd1d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cced0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cf4d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cf950>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cd050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cee10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6ce790>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cc3d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6cd250>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6ce050>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf40c250>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6cdb10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf6ceb50>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf747a10>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf697310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf696d90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf697190>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf695410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6963d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f7dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f5810>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f7450>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2395350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f6f10>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2396a90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf694350>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf695ad0>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf3f52d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f7310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f4c90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f6690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f5fd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f7650>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f4c50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f7fd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f6850>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2395a90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f5510>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3f4790>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf96c790>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf6245d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf625fd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf627350>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6243d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf624690>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2395290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf627410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3f6010>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ae4d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ae610>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3afbd0>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf3afe10>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf3ae490>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3acf10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3ae310>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf3ac090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ac6d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ae350>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2395b10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ae890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3ad290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3afdd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf8c4c50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8c7850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf52d450>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6a2b10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6a22d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf6a0390>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf37afd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf3792d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf379690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf37a390>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf37a8d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf378090>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf37bd10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf37b590>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf37b910>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf37bc50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf37bfd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf37a590>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2397490>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c1bbd850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf6a3e10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf378f10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf3789d0>,\n",
              " <unstructured.documents.elements.Image at 0x7884bf378410>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf3795d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884c2397650>,\n",
              " <unstructured.documents.elements.FigureCaption at 0x7884bf37a090>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf6fdb50>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf918310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e6e90>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf7e5b90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e4790>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf7e6790>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf919c50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7e4ed0>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf6fc450>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf304390>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf307dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf304d50>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf304290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf89db50>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf8d2d10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf91ac50>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf89ed90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf307610>,\n",
              " <unstructured.documents.elements.Table at 0x7884bf7ed0d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf91ad90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7eca50>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7ed190>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf339a10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33bc90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33ad10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf33ac90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf33af90>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33a310>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf339cd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf339110>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33b550>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33abd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf338d50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf33a550>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33bf90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884c22d8710>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf45b050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf4598d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf45ba90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf459c90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf45b610>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5d9050>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9185d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf458c10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf459190>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf33a5d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf33a650>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf339910>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf33b050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5da4d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5db450>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5dbcd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf4c2490>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf4c06d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9b9fd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6244f50>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6246f90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6246b10>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6245ad0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6244590>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6244790>,\n",
              " <unstructured.documents.elements.Title at 0x7884a6247350>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b2cd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b25d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf5b36d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf918410>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf3382d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9baf50>,\n",
              " <unstructured.documents.elements.Title at 0x7884a62443d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a6244990>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5d8110>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf5b2f50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b2190>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf5b3cd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5b2750>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b3050>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf759550>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf759cd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf759ed0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf75af90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf75acd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf9c6510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf9c5910>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf918a90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5dac10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7596d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf7583d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5b3850>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5b27d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6259550>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6259290>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf918bd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5b3f50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a625b890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6259050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6258e10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6259e10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf919790>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a6258b10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a625b290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62da790>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d8690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62dbe50>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62da850>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf990050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d8a90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d9f10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d9850>,\n",
              " <unstructured.documents.elements.Title at 0x7884a62d9510>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d9290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d94d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d8f50>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf9918d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d8390>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a62d9ed0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620c6d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf990310>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620f3d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620d290>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620d750>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf990dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620e8d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620d5d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a620d1d0>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf993fd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884a620e3d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf9f32d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9f2850>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9f1810>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9f1690>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36d3d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36c6d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36dad0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36d8d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36d390>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36fe10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf36d010>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf992e50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf9f3290>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36f890>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36ed50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b9b10>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5b9850>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf5ba6d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8f6910>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8f6310>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8f5290>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8f7fd0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621f090>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621df10>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf993ad0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf8f7110>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884bf36c8d0>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621ec90>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621d110>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621da50>,\n",
              " <unstructured.documents.elements.ListItem at 0x7884a621d390>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf990b50>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf36de10>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf40e010>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884a621c750>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf656890>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf655dd0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf657690>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf655cd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884c3404c10>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f1090>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f0610>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f20d0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f3890>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7d1b90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f3050>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7d0ad0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x7884bf5f2cd0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf8d24d0>,\n",
              " <unstructured.documents.elements.Title at 0x7884bf7d0510>,\n",
              " <unstructured.documents.elements.Text at 0x7884bf7d2510>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Header = []\n",
        "Footer = []\n",
        "Title = []\n",
        "NarrativeText = []\n",
        "Text = []\n",
        "ListItem = []\n",
        "\n",
        "for element in raw_pdf_element:\n",
        "    if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
        "        Header.append(str(element))\n",
        "    elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
        "        Footer.append(str(element))\n",
        "    elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
        "        Title.append(str(element))\n",
        "    elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "        NarrativeText.append(str(element))\n",
        "    elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
        "        Text.append(str(element))\n",
        "    elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
        "        ListItem.append(str(element))\n"
      ],
      "metadata": {
        "id": "1eT3a73naCjb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NarrativeText"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7wVSSvcabQd",
        "outputId": "a19994a8-bb67-4b0d-8eda-35ac0e87bbb5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Submitted in partial fulfillment of the requirements for the degree of',\n",
              " '21BCE0250 21BDS0094 21BDS0115',\n",
              " 'Raghav Mittal Poorvi Kejriwal Sarthak Punj',\n",
              " 'Associate Professor Grade 2',\n",
              " 'School of Computer Science and Engineering (SCOPE)',\n",
              " 'I am deeply grateful to the management of Vellore Institute of Technology (VIT) for providing me with the opportunity and resources to undertake this project. Their commitment to fostering a conducive learning environment has been instrumental in my academic journey. The support and infrastructure provided by VIT have enabled me to explore and develop my ideas to their fullest potential.',\n",
              " 'My sincere thanks to Dr. Ramesh Babu K, the Dean of the School of Computer Science and Engineering (SCOPE), for his unwavering support and encouragement. His leadership and vision have greatly inspired me to strive for excellence. The Dean’s dedication to academic excellence and innovation has been a constant source of motivation for me. I appreciate his efforts in creating an environment that nurtures creativity and critical thinking.',\n",
              " 'I express my profound appreciation to Dr. Murali S, the Head of the Computer Science with specialization in Data Science, for his/her insightful guidance and continuous support. His expertise and advice have been crucial in shaping the direction of my project. The Head of Department’s commitment to fostering a collaborative and supportive atmosphere has greatly enhanced my learning experience. His constructive feedback and encouragement have been invaluable in overcoming challenges and achieving my project goals.',\n",
              " 'I am immensely thankful to my project supervisor, Dr. Raja SP, for his dedicated mentorship and invaluable feedback. His patience, knowledge, and encouragement have been pivotal in the successful completion of this project. My supervisor’s willingness to share his expertise and provide thoughtful guidance has been instrumental in refining my ideas and methodologies. His support has not only contributed to the success of this project but has also enriched my overall academic experience.',\n",
              " 'Thank you all for your contributions and support.',\n",
              " 'Raghav Mittal Poorvi Kejriwal Sarthak Punj',\n",
              " 'The rapid growth of technology has made the metaverse more popular, and its potential is enormous, though we are only beginning to explore it. Simply put, the metaverse is a virtual space where people can interact, socialize, work, and engage in activities using digital avatars, similar to what they do in real life. This immersive environment is a mix of virtual reality (VR), augmented reality (AR), and the internet. VR allows users to be fully immersed in computer- generated worlds through headsets, while AR overlays digital elements onto the real world, enhancing the experience.',\n",
              " 'This paper focuses on finding new ways to integrate healthcare into the metaverse by addressing some of the key challenges holding back its progress. One challenge is reducing delays in data transfer, which is critical for quick and reliable communication between doctors and patients. Another issue is the high cost of VR headsets, which limits access for many people. Making these headsets more affordable and widely available would open up more possibilities for using the metaverse in healthcare. Additionally, advanced technology can be used to better predict diseases based on symptoms, allowing for earlier and more accurate diagnoses.',\n",
              " 'Another exciting possibility the metaverse brings to healthcare is the ability for doctors to practice surgeries and procedures on digital avatars before performing them on real patients. This could help improve medical training and reduce the risks associated with complicated surgeries. While the metaverse holds great promise to transform healthcare, there is still much research needed to fully unlock its potential. The future of healthcare in the metaverse looks bright, but more exploration and development are required to make it a reality for everyone.',\n",
              " 'Keywords - Metaverse; Augmented reality; Virtual realit',\n",
              " 'The metaverse has the potential to transform healthcare in profound ways. This paper focuses on turning the virtual world into a reality for healthcare, aiming to address key barriers that limit its full use in this field. In healthcare, timely and reliable communication is crucial. Delays can cost lives. The first approach in this paper suggests reducing data transfer delays and improving reliability, creating a secure, fast network for better communication between doctors, nurses, and patients.',\n",
              " 'Another challenge is the high cost of VR headsets, which are necessary to access the metaverse. The second approach proposes methods to lower the price of these headsets while ensuring companies don’t suffer financial losses.',\n",
              " 'The third issue is the late detection of diseases. This paper introduces a model that uses symptoms and medical data to predict diseases early, which can be life-saving for conditions like cancer.',\n",
              " 'Lastly, the paper explores how virtual environments can allow doctors to practice surgeries on digital patient avatars before performing them on real patients. This would improve surgery success rates and offer medical students a practical learning tool. While some solutions are offered, much more needs to be explored to unlock the full potential of the metaverse in healthcare.',\n",
              " 'The metaverse represents a groundbreaking opportunity to revolutionize healthcare, offering the potential to transform how medical services are delivered, experienced, and accessed by patients and healthcare professionals alike. This paper delves deeply into the challenges and possibilities of integrating healthcare into the metaverse, highlighting key areas where technological advancements and innovative approaches can address current barriers to the widespread implementation of virtual healthcare solutions. The concept of the metaverse in healthcare is not just about creating a virtual space where doctors and patients can meet; it is about fundamentally changing how healthcare operates by enhancing accessibility, improving patient outcomes, and making healthcare more efficient, inclusive, and effective. However, despite the promise that the metaverse holds for healthcare, its practical application faces several critical challenges, all of which this paper seeks to address in order to unlock its full potential.',\n",
              " 'First and foremost, one of the biggest challenges for integrating healthcare into the metaverse is the need for a highly reliable and fast data transfer network. In healthcare, where timely and accurate communication is absolutely essential, the ability to transmit and receive medical data in real-time is of utmost importance. Delays in data transmission can have dire consequences for patients, particularly in emergency situations where decisions need to be made quickly and accurately. Medical professionals must have access to up-to-date patient information, including diagnostic results, medical histories, and live monitoring data, to make informed decisions in real-time. Without a fast, secure, and reliable network infrastructure to',\n",
              " 'support these data requirements, the effectiveness of virtual healthcare services would be severely limited. The first approach outlined in this paper addresses this challenge by advocating for the creation of a robust network that can handle the massive volumes of data generated by healthcare applications, ensuring that communication between doctors, nurses, and patients is seamless and instantaneous. This solution not only focuses on the speed of data transfer but also emphasizes the importance of security and data integrity, ensuring that sensitive patient information is protected from unauthorized access or breaches. By creating such a network infrastructure, the foundation for virtual healthcare in the metaverse would be firmly established, enabling healthcare professionals to provide care remotely with confidence, regardless of geographical location or time zone differences.',\n",
              " 'Another significant barrier to the widespread adoption of metaverse-based healthcare is the high cost of the technology required to access it. Virtual reality (VR) headsets, which are essential for immersive interactions within the metaverse, remain prohibitively expensive for many individuals and healthcare institutions. This creates a financial obstacle that limits access to virtual healthcare services, especially for underserved populations or low-income patients who would benefit most from the convenience and accessibility that the metaverse could offer. The cost of VR headsets also places a burden on healthcare institutions that must invest heavily in this technology in order to implement metaverse-based healthcare solutions. In this paper, the second approach proposes several strategies for making VR headsets more affordable without compromising their performance or the financial stability of the companies producing them. The approach includes researching new manufacturing methods, exploring the use of less expensive materials, and optimizing production processes to reduce costs. Additionally, partnerships between manufacturers, healthcare providers, and government organizations are encouraged to support the development of more affordable VR solutions, ensuring that healthcare systems can integrate this technology into their operations without incurring excessive costs. By lowering the cost of VR headsets, the paper envisions a future where healthcare providers—both large hospitals and small clinics—can offer virtual consultations, remote monitoring, and therapeutic services to a much wider range of patients, including those in rural areas, elderly individuals, and individuals with disabilities who may have difficulty traveling to physical healthcare facilities. Moreover, the reduced cost of VR equipment could also make it possible for medical institutions to invest in VR-based medical training, allowing healthcare professionals to practice and refine their skills in a safe, controlled environment before performing procedures on real patients.',\n",
              " 'In addition to making VR technology more accessible, this paper also addresses the issue of early disease detection, which is critical to improving patient outcomes and reducing mortality rates. Diseases such as cancer, heart disease, and neurological disorders are often diagnosed too late, when they have progressed to advanced stages that are more difficult—and sometimes impossible—to treat. Timely diagnosis is essential to ensuring that patients receive the most effective treatments possible and have the best chance of recovery. To address this challenge, the paper introduces a predictive model that leverages advanced analytics and real- time medical data to detect signs of diseases at an early stage. By analyzing symptoms, medical histories, lifestyle factors, and genetic predispositions, the model can identify potential health risks before they manifest as serious medical conditions. This proactive approach to healthcare',\n",
              " 'would allow doctors to intervene earlier, providing treatments that could slow or even prevent the progression of diseases. By integrating this predictive model into the metaverse, healthcare professionals would have a powerful tool to improve the quality of care, reduce mortality rates, and improve long-term patient outcomes. The model would be continuously updated with new medical research and data, ensuring that healthcare professionals have access to the most up- to-date and accurate information for diagnosis and treatment. This approach could fundamentally change the way healthcare is delivered, shifting from a reactive system focused on treating illness to a proactive system focused on preventing it.',\n",
              " 'Lastly, this paper explores the potential for using the metaverse to revolutionize medical training and surgical practice. The ability to create highly realistic virtual environments where doctors, medical students, and other healthcare professionals can practice complex procedures offers a unique opportunity to improve medical education and enhance the skills of healthcare providers. By using digital patient avatars and simulated medical scenarios, healthcare professionals can refine their surgical techniques, rehearse procedures, and gain hands-on experience in a risk-free virtual environment. This virtual training platform would not only allow practitioners to gain experience with common procedures but also enable them to practice rare or high-risk surgeries that they may not encounter frequently in real life. The ability to simulate medical procedures before performing them on actual patients would reduce the likelihood of errors and improve the success rates of surgeries, leading to better patient outcomes. The paper suggests that these virtual training environments could be incorporated into medical school curricula, continuing education programs for healthcare professionals, and even real-time medical simulations during surgeries. This innovative approach to medical education and training could significantly improve the quality of care by ensuring that healthcare professionals are better prepared to handle complex cases and provide the best possible treatment to their patients.',\n",
              " 'In conclusion, while this paper presents several innovative approaches to integrating healthcare into the metaverse, it also acknowledges that much work remains to be done to realize the full potential of virtual healthcare. The four key areas addressed—improving communication through high-speed, reliable networks, making VR technology more affordable, developing predictive models for early disease detection, and providing virtual environments for medical training—represent important steps toward achieving the vision of a fully integrated metaverse healthcare system. However, there are many more aspects of healthcare that the metaverse could impact, including mental health care, remote patient monitoring, personalized treatment plans, and even the management of chronic conditions. As the technology continues to evolve and new solutions emerge, the possibilities for innovation in the healthcare sector are limitless. With continued research, development, and collaboration between healthcare providers, technology companies, and policymakers, the dream of a metaverse-powered healthcare system can become a reality, transforming the way healthcare is delivered, improving access to care, and ultimately enhancing the health and well-being of individuals around the world. The metaverse holds the potential to be a technological breakthrough that will reshape the future of healthcare, providing patients with better access to care, improving treatment outcomes, and ensuring that medical professionals have the tools and skills they need to provide the highest quality care.',\n",
              " 'Healthcare is vital, and it\\'s our responsibility to improve future living standards. In many small towns and villages, people suffer from poor healthcare facilities. Often, patients can\\'t reach hospitals in time due to long travel distances in critical situations. Imagine introducing a \"meta van\" to these areas, offering virtual healthcare services.',\n",
              " 'With the meta van, patients could use shared VR headsets to consult doctors who can closely study their symptoms. This would allow them to receive proper medical guidance without the need for long travel, reducing stress and aiding recovery. This paper aims to tackle the early challenges of bringing healthcare into the metaverse, ensuring even remote areas can enjoy top-quality medical services from home.',\n",
              " \"As technology advances, it's essential to explore its full potential and make it affordable for everyone. The metaverse could revolutionize healthcare access, especially for those in urgent need. Since Mark Zuckerberg introduced the term “metaverse” in 2021, its applications have expanded, including in healthcare. The rising demand for better treatments and solutions for rare diseases makes the metaverse appealing in this field.\",\n",
              " 'This paper explores strategies to make the metaverse central to healthcare by using data analysis and mathematical models to solve common problems.',\n",
              " 'Since healthcare leaves a great impact on our lives, we being responsible for the future lives on Earth must take into our hands the task of making their standard of living higher. Today, many small towns and villages see their loved ones struggling for life because of poor healthcare facilities. Sometimes, people succumb to death even before they reach a doctor because of having to travel long distances in severe health conditions. Imagine if we try to implement the concept of a meta van in every small town and village.',\n",
              " 'Patients can come to the meta van, use the common VR headset and get advised in an appropriate manner having all their symptoms, body parts and problems closely observed and studied. They can be medically assisted in a proper manner and the implementing healthcare in metaverse so that one fine day, every corner of the world can experience top- notch medical services from the comfort of homes. Technology is advancing and we believe that we must positively and fully exploit its fruit.',\n",
              " 'Firstly, we should try and unleash the potential of meta. Then we must extend our capabilities to make it affordable in almost every home. This can revolutionise the way we live and be an aid to those who struggle for life. Healthcare is a sphere where people do not step back to yearn for the best. Therefore, if we can make it affordable, trustworthy and accessible, there is nothing like it. Mark Zuckerburg coined the term ‘metaverse’ in 2021 and ever since it is trying to capture all domains. New concepts and techniques are being tried and tested to transform the idea to a fully running model. The ever-increasing demand to improve treatment outcomes and find solutions to rare diseases made metaverse popular in the health sector. The idea of this paper is to devise a strategy which will help metaverse to be the heart of healthcare services.',\n",
              " 'Data analysis is a crucial part of this process and this paper tries to cover different datasets to explain the theories and study the best solutions that cater all problems. Maths is very clearly the basis of this paper’s model and a vast number of mathematical concepts are used to support the techniques discussed. ir journey to recovery can be less painful. This paper aims to address the initial hurdles of this paper’s model and a vast number of mathematical concepts are used to support the techniques discussed.',\n",
              " 'Healthcare is an essential pillar of society, and it is our collective responsibility to work towards improving the future living standards of individuals across the world. In many small towns and rural villages, people continue to suffer from inadequate healthcare facilities that are not equipped to handle critical medical situations. The gap in healthcare access is especially dire in remote areas where patients often face the challenge of reaching hospitals in time, sometimes even losing their lives before they can receive the treatment they desperately need. These challenges are exacerbated by long travel distances, a lack of immediate medical intervention, and poor infrastructure that makes it difficult for people in such areas to access timely healthcare services. However, imagine the transformative potential of a new concept— the \"meta van\"—which could bring virtual healthcare services directly to these communities. The concept of a meta van, which can deliver healthcare through the metaverse, could drastically change the medical landscape, particularly for people living in underserved regions.',\n",
              " 'In this vision, patients living in these isolated areas could visit a specially equipped mobile unit—the meta van—and use shared VR headsets to consult with experienced doctors remotely. Through this technology, doctors would have the ability to closely observe the patient’s symptoms, provide accurate diagnoses, and offer treatment plans, all from a virtual environment. This would enable patients to receive proper medical guidance without the need for long and sometimes dangerous travel, particularly during critical health situations. The ability to access healthcare services remotely would significantly reduce the stress and physical strain on patients, ultimately contributing to a faster recovery and improved quality of care. The meta van would bridge the vast distances that currently separate these remote communities from world-class medical services, making healthcare more accessible, equitable, and efficient for all. This paper, in particular, aims to address some of the early challenges involved in bringing healthcare into the metaverse, focusing on ensuring that even those in the most remote corners of the world can receive top-quality medical services from the comfort of their homes.',\n",
              " 'As technology continues to advance, it becomes increasingly crucial to explore and harness its full potential. In particular, the metaverse has the power to radically transform healthcare delivery, offering new avenues for accessibility and improved care. However, for this transformation to occur on a global scale, it is necessary to make these advancements not only possible but affordable and accessible to all. The metaverse could be the key to revolutionizing healthcare access, especially for people who need urgent care, and especially for those who live in areas where conventional medical services are simply not available or easily accessible. The concept of the metaverse was introduced by Mark Zuckerberg in 2021, and since then, it has grown beyond its initial scope of virtual reality gaming into a broad range of applications, including healthcare. This expansion into healthcare comes at a time when there is a growing demand for better medical treatments and innovative solutions, particularly',\n",
              " 'for rare diseases, chronic conditions, and aging populations. As the need for improved healthcare becomes more urgent, the metaverse offers a new and exciting opportunity to address these challenges.',\n",
              " 'This paper delves into several strategies that aim to make the metaverse the central hub for healthcare services. By utilizing data analysis and mathematical models, the paper explores how these technologies can be applied to solve the common problems faced by healthcare systems. One of the most significant problems is the accessibility of healthcare in rural and underdeveloped areas. Through the use of the metaverse, patients would no longer be limited by geographical constraints or the lack of nearby healthcare facilities. The concept of the meta van could be implemented in small towns and villages, ensuring that people who live in remote areas can access the same high-quality healthcare as those living in urban centers. This would bridge the gap in healthcare equity, ensuring that no one is left behind, regardless of where they live.',\n",
              " 'Furthermore, the potential of the metaverse goes beyond just providing remote consultations. By incorporating virtual reality (VR) technologies, patients could undergo virtual assessments, experience real-time interactions with healthcare providers, and receive personalized care and treatment plans tailored to their needs. The meta van could be equipped with the necessary tools to perform medical tests, such as vital sign monitoring and diagnostics, all connected to a network that enables real-time communication with medical professionals. This innovative approach could provide patients with immediate access to care, reducing the time and resources currently required for in-person visits to healthcare facilities. It would also provide an essential resource for people who struggle with mobility issues or those who are elderly or disabled, enabling them to receive care without needing to leave their homes or travel long distances.',\n",
              " 'As technology continues to evolve, it is important to ensure that these innovations are made affordable and accessible to as many people as possible. Making VR headsets and other virtual reality equipment affordable is critical to the widespread adoption of metaverse-based healthcare. This paper suggests that developing cost-effective methods for manufacturing VR headsets and other related technologies would be a key component in making the metaverse a viable and sustainable solution for healthcare delivery. This includes exploring alternative materials, improving production processes, and finding ways to drive down costs without sacrificing the quality of the technology. If VR equipment can be made affordable and accessible, the reach of virtual healthcare could expand exponentially, allowing millions of people who would otherwise not have access to high-quality care to benefit from these advancements.',\n",
              " \"Additionally, the paper emphasizes the importance of data analysis and mathematical models in shaping the metaverse's role in healthcare. By using predictive analytics, medical professionals can identify early warning signs of disease and intervene before conditions worsen. For example, early detection of cancers, heart disease, or diabetes could significantly improve patient outcomes by allowing for prompt treatment and personalized care plans. Mathematical models and algorithms can be applied to analyze large datasets of patient information, providing doctors with accurate predictions about health risks and the likelihood\",\n",
              " 'of disease progression. This paper explores how these models can be integrated into virtual healthcare systems, ensuring that healthcare providers have the information they need to make informed decisions and deliver the best possible care.',\n",
              " 'Furthermore, the paper explores the possibility of using the metaverse for medical training, allowing doctors and healthcare professionals to practice surgeries and other medical procedures on digital patient avatars. This would provide a safe and controlled environment for practitioners to hone their skills, reduce errors, and improve the success rates of surgeries, ultimately leading to better patient outcomes. The ability to simulate medical procedures in a virtual environment would also provide medical students and professionals with the opportunity to practice rare or complex cases that they might not encounter in their clinical training.',\n",
              " 'In conclusion, this paper presents a vision for the future of healthcare, where the metaverse plays a central role in delivering accessible, affordable, and high-quality care to people around the world. The idea of the meta van—bringing healthcare to remote areas through virtual reality—is just one example of how the metaverse can revolutionize healthcare delivery. By overcoming challenges such as affordability, access, and data analysis, the metaverse has the potential to transform the healthcare landscape and improve the lives of millions of people, particularly those living in rural or underserved communities. As we continue to develop these technologies, it is essential to ensure that they are not only innovative but also equitable, sustainable, and accessible to everyone. The future of healthcare lies in harnessing the full potential of the metaverse, creating a system where healthcare is available to all, regardless of location or socioeconomic status.',\n",
              " 'This project focuses on integrating healthcare into the metaverse, addressing key challenges that limit its practical implementation. The boundaries of this study include reducing latency and improving the speed and reliability of data transfer in virtual healthcare environments. By creating a secure and fast network, medical professionals will be able to communicate effectively with patients in real time, which is critical for emergency situations.',\n",
              " 'Additionally, this project looks into making virtual reality (VR) headsets more affordable, as they are essential for accessing the metaverse. The aim is to provide solutions that reduce costs without affecting the financial stability of companies producing the equipment.',\n",
              " 'Another important aspect is the development of prediction models that enable the early detection of diseases. This helps doctors diagnose and treat conditions before they worsen, potentially saving lives. Finally, the project explores creating virtual environments where doctors can practice surgeries on digital patient avatars, improving their skills and reducing risks to real patients.',\n",
              " 'Overall, the extent of the project covers these four areas, aiming to provide a comprehensive solution to integrating healthcare services into the metaverse for improved',\n",
              " 'global access and quality.',\n",
              " 'This project is centered on the integration of healthcare services into the metaverse, with the goal of overcoming the various obstacles that currently prevent its practical and widespread implementation. The metaverse has the potential to revolutionize healthcare by providing new avenues for communication, treatment, and training, but several significant challenges need to be addressed before this vision can become a reality. The scope of this study is extensive, focusing on the four critical areas that are crucial to making virtual healthcare in the metaverse both feasible and effective. By addressing these challenges, the project aims to create a robust framework for integrating healthcare services into virtual reality, thus improving global access to healthcare and enhancing the quality of care provided to patients worldwide.',\n",
              " \"One of the most pressing issues that the project seeks to tackle is the problem of latency and data transfer speeds within virtual healthcare environments. Latency, or the delay in communication between systems, is a major concern in healthcare, particularly when real-time data exchange is essential for accurate diagnoses and timely interventions. In emergency medical situations, every second counts, and any delay in transmitting critical medical data— such as a patient's vital signs, lab results, or diagnostic imaging—could jeopardize the patient's chances of survival or recovery. Therefore, the project places significant emphasis on reducing latency and improving the speed and reliability of data transfer in the metaverse to ensure that healthcare professionals can communicate with patients and other healthcare providers instantly and without interruption. This is especially crucial for emergency scenarios, where immediate medical attention is necessary. A fast, reliable, and secure network infrastructure is paramount for supporting the vast amounts of medical data that must be transmitted in real- time across virtual healthcare environments. By creating a robust and high-performance network capable of handling the data transmission demands of virtual healthcare, this project aims to create a more efficient and effective healthcare delivery system in the metaverse, ensuring that medical professionals can provide immediate assistance to patients, regardless of geographical location.\",\n",
              " 'Another key aspect of this project is the goal of making virtual reality (VR) headsets more affordable and accessible to a wider range of users. VR headsets are an essential component of the metaverse, enabling healthcare professionals and patients to interact within a fully immersive virtual environment. However, despite their transformative potential, VR headsets and related technologies are often prohibitively expensive, creating a significant barrier to entry for many healthcare providers and patients. The high cost of VR equipment can prevent healthcare institutions, especially those in lower-income regions, from adopting metaverse-based healthcare solutions, further exacerbating disparities in healthcare access. Moreover, the cost of VR headsets can be a barrier for individual patients who may not be able to afford the technology, even though it could vastly improve their access to healthcare services. In order to overcome this obstacle, the project explores innovative ways to reduce the cost of VR headsets and related equipment without compromising the financial viability of companies that manufacture these devices. This includes finding more cost-effective manufacturing techniques, exploring new materials, and improving the efficiency of the supply',\n",
              " 'chain. The ultimate goal is to make VR technology more affordable and accessible, thus enabling healthcare professionals and patients from all walks of life to participate in the metaverse healthcare ecosystem, democratizing access to high-quality medical services, and enhancing healthcare equity across the globe.',\n",
              " \"In addition to improving the accessibility of VR technology, another critical area of focus is the development of advanced predictive models that enable the early detection of diseases. Early diagnosis is crucial for preventing the progression of many medical conditions and significantly improving patient outcomes. In traditional healthcare systems, delayed diagnoses can result in more advanced stages of illness, which can be much harder to treat and may lead to higher mortality rates. By leveraging the power of the metaverse and its associated technologies, this project aims to develop predictive models that can analyze vast amounts of medical data—such as genetic information, patient history, and real-time health monitoring data—and identify patterns that suggest the early onset of diseases. These predictive models could alert doctors to potential health issues before they become serious, allowing for earlier intervention, more effective treatment, and, in many cases, saving lives. For example, through continuous monitoring of patient health data in virtual environments, the metaverse could enable healthcare providers to detect the early stages of chronic conditions like diabetes, hypertension, or even cancer. By identifying these conditions at an earlier stage, doctors could intervene more quickly and offer treatment plans that prevent further deterioration of the patient's health. This approach has the potential to revolutionize how healthcare is delivered, shifting the focus from reactive treatment to proactive prevention and early intervention, ultimately reducing the burden of disease and improving overall public health outcomes.\",\n",
              " 'Finally, this project explores the creation of immersive virtual environments where medical professionals can practice complex procedures and surgeries on digital patient avatars. Surgery is an inherently high-risk field, with even the most experienced surgeons facing the potential for errors, especially when performing difficult or rare procedures. In a traditional setting, mistakes made during surgery can have serious consequences for the patient, including complications, extended recovery times, or even death. However, the metaverse offers an innovative solution by providing a safe and controlled environment in which medical professionals can practice surgeries and refine their skills without putting actual patients at risk. By using digital patient avatars that simulate real-world anatomy and medical conditions, surgeons can perform virtual surgeries, learn new techniques, and gain valuable experience in a risk-free setting. This will not only enhance the skills of healthcare professionals but also increase their confidence and competence when performing surgeries in the real world. In addition, the ability to practice in a virtual environment can provide healthcare workers with access to a broader range of training scenarios, including rare or complex cases that they may not encounter in their daily practice. This virtual training model has the potential to greatly improve the quality of medical education and training, ultimately leading to better patient outcomes and a reduction in medical errors.',\n",
              " 'In conclusion, the scope of this project is both broad and ambitious, covering four key areas that are essential to the integration of healthcare services into the metaverse: reducing latency and improving data transfer speeds, making VR technology more affordable,',\n",
              " 'developing predictive models for early disease detection, and creating virtual environments for surgical practice. By addressing these critical challenges, the project aims to provide a comprehensive and sustainable solution to the integration of healthcare services into the metaverse. If successful, the outcomes of this project could lead to a significant transformation in the way healthcare is delivered, providing improved access to medical services for patients around the world, enhancing the training and skills of healthcare professionals, and ultimately improving the quality of care. With continued research, innovation, and collaboration, the metaverse has the potential to revolutionize healthcare and create a more equitable, efficient, and accessible global healthcare system. The solutions proposed in this project represent an important step toward realizing this vision and unlocking the full potential of the metaverse for the future of healthcare.',\n",
              " 'This project is centered on the integration of healthcare services into the metaverse, a highly ambitious initiative that seeks to revolutionize healthcare delivery by overcoming multiple key barriers that currently impede the practical implementation of metaverse technologies in the medical field. The metaverse, with its potential to create immersive digital environments that mimic real-world experiences, offers unparalleled opportunities for transforming how healthcare is accessed and delivered, with the possibility to drastically improve both patient care and healthcare professional training. However, realizing this potential requires addressing several complex challenges that stem from technological limitations, high costs, and accessibility issues that currently prevent the broad application of virtual healthcare. Therefore, this project is designed to tackle these obstacles head-on, focusing on four primary areas that are crucial for successfully integrating healthcare into the metaverse. By addressing these critical components, the project hopes to create a sustainable and scalable model for virtual healthcare that can be accessed by people globally, regardless of their location or financial situation.',\n",
              " 'One of the most pressing challenges this project aims to solve is the issue of latency',\n",
              " \"and the speed and reliability of data transfer within virtual healthcare environments. Latency, which refers to the delay in transmitting and receiving data between systems, is a major concern in healthcare, especially when it comes to real-time medical applications. In virtual healthcare, particularly in emergency medical situations, real-time communication is essential for providing timely interventions that can make the difference between life and death. If there is any delay in transmitting critical medical information, such as a patient's vital signs, lab results, or diagnostic images, it can result in delayed treatment, which could lead to worsening health conditions or even fatalities. To overcome this issue, the project places significant emphasis on developing a fast, secure, and reliable network infrastructure that can support the massive data exchange demands of virtual healthcare environments. This will involve improving current internet protocols, enhancing bandwidth capacity, and developing more robust technologies that ensure the seamless transfer of medical data, allowing healthcare professionals to communicate with patients and other medical personnel instantly. Furthermore, improving the network's reliability is critical for maintaining continuous and uninterrupted care, especially in remote or rural areas where healthcare access may be limited. By focusing on reducing latency and improving data transfer speeds, this project hopes to ensure that healthcare providers can offer high-quality care to patients in real time, thus bridging the geographical gap that often\",\n",
              " 'limits healthcare accessibility.',\n",
              " 'Another major area of focus for this project is making virtual reality (VR) technology',\n",
              " 'more affordable and accessible to healthcare providers and patients. VR headsets, which are essential for interacting with the metaverse, are often prohibitively expensive, creating a significant barrier to their adoption in healthcare settings. Currently, the high cost of VR equipment restricts its usage to a limited number of healthcare institutions and patients, especially those in lower-income regions. This financial barrier prevents a large segment of the population from accessing the transformative benefits of metaverse healthcare services, exacerbating the global inequities in healthcare access. Additionally, the high cost of VR equipment is a challenge for healthcare providers, particularly small clinics or rural hospitals, who may struggle to afford the initial investment in these technologies. In response to these issues, the project explores innovative ways to reduce the cost of VR headsets and other related equipment while maintaining the financial viability of the companies that produce them. The project aims to find cost-effective manufacturing methods, optimize supply chains, and identify alternative materials that can reduce production costs without compromising the performance or quality of the devices. By lowering the price point of VR headsets and other associated technologies, the project seeks to make these tools more accessible to a wider range of healthcare providers, from large hospitals to small community clinics, as well as individual patients who may benefit from virtual healthcare services. In doing so, the project hopes to democratize access to high-quality healthcare and virtual services, ensuring that healthcare innovation can reach all socioeconomic groups, regardless of their financial means.',\n",
              " 'In addition to making VR technology more affordable, another crucial aspect of this',\n",
              " \"project is the development of predictive models for early disease detection. Early diagnosis of medical conditions is one of the most important factors in improving patient outcomes and reducing mortality rates. In traditional healthcare systems, delays in diagnosis often lead to the progression of diseases to advanced stages, which can be much more difficult and costly to treat. Many chronic diseases, such as cancer, diabetes, and cardiovascular conditions, can be managed more effectively if detected in their early stages, preventing complications and improving the quality of life for patients. The metaverse, with its ability to create immersive and interactive environments, offers a unique opportunity to enhance diagnostic capabilities through the use of predictive models that analyze vast amounts of medical data. By integrating machine learning, artificial intelligence (AI), and big data analytics, these predictive models can identify early signs of diseases based on a patient's medical history, genetic information, lifestyle factors, and real-time health data. For instance, through continuous monitoring of a patient's vital signs, lab results, and other health metrics in a virtual environment, doctors could detect the early onset of diseases like hypertension, diabetes, or even more serious conditions like cancer. The predictive model could then alert healthcare providers to potential issues before they become critical, allowing for earlier intervention and reducing the risk of adverse health outcomes. The use of these models could significantly reduce mortality rates by enabling doctors to intervene proactively, providing treatment at an earlier and more manageable stage of the disease.\",\n",
              " 'Finally, the project explores the creation of virtual environments where medical',\n",
              " 'professionals can practice surgeries and other complex medical procedures using digital patient avatars. Surgery is an inherently high-risk endeavor, and even the most experienced surgeons can encounter challenges when performing complex or unfamiliar procedures. Surgical errors can lead to serious complications for patients, including extended recovery times, increased risk of infection, and, in some cases, death. The metaverse offers an innovative solution by providing a safe and controlled environment for surgeons to practice their skills without putting actual patients at risk. Using digital patient avatars, which simulate human anatomy and physiological responses, surgeons can rehearse procedures, test new techniques, and refine their skills in a risk-free virtual setting. This virtual practice can help healthcare professionals become more proficient in their craft, leading to improved patient outcomes and fewer medical errors. Additionally, virtual surgical training can provide healthcare workers with access to a wider range of scenarios, including rare or highly complex cases that they may not otherwise encounter in their daily practice. The ability to simulate various medical conditions and patient responses can help doctors gain valuable experience and prepare for challenging surgeries, improving their confidence and competence. By providing a platform for continuous medical education and training, the project aims to improve the overall quality of healthcare services and reduce the occurrence of medical errors, ultimately leading to safer and more effective patient care.',\n",
              " 'In conclusion, the scope of this project is expansive and multifaceted, encompassing',\n",
              " 'several crucial areas of development that are necessary for the successful integration of healthcare services into the metaverse. By focusing on reducing latency, improving data transfer speeds, making VR technology more affordable, developing predictive models for early disease detection, and creating virtual environments for surgical practice, the project aims to address the critical barriers that currently prevent the widespread adoption of metaverse healthcare. The successful implementation of these solutions could lead to a transformative shift in healthcare, making it more accessible, efficient, and effective for patients and healthcare professionals alike. If successful, the project could significantly improve the quality of healthcare worldwide, offering innovative solutions for disease prevention, diagnosis, treatment, and medical training. With continued research, collaboration, and technological advancement, the metaverse has the potential to become an integral part of the global healthcare landscape, revolutionizing the way healthcare services are delivered and creating a more equitable and accessible system for all. Through this project, the vision of a future where healthcare is accessible, affordable, and effective for everyone, regardless of their location or socioeconomic status, can become a reality.',\n",
              " 'The potential of the metaverse in healthcare is being explored by various experts, focusing on its diverse applications in medical education, collaboration, and patient care. Jane',\n",
              " \"Thomason and Sudip Bhattacharya emphasize the metaverse’s role in collaborative spaces for health workers, particularly in rural Indian healthcare, promoting resource sharing and integration. Ge Wang introduces 'meTAI,' a platform for medical imaging and diagnosis, focusing on raw data sharing and virtual scanning, while Yeong-Tae Song proposes a metaverse-based healthcare system that incorporates a layered digital twin model for real-time monitoring and analysis.\",\n",
              " \"Yingchun Zeng investigates metaverse applications in cancer care, addressing ethical and legal challenges in its implementation. Antonio Cerasa's work focuses on mental health, using the metaverse to provide personalized treatments and foster social interaction. Ganapathy offers a simplified overview of metaverse applications in healthcare, discussing the advantages and disadvantages in clinical practice. Tzu-Chi Wu explores the use of AR/VR in emergency medicine for clinical training, while Yogesh K. Dwivedi highlights the potential of the metaverse in the physical world and proposes future research agendas for further exploration. Brenda K. Wiederhold highlights the widespread impact of the metaverse in healthcare, with a focus on its influence on the sector.\",\n",
              " 'Omid Moztarzadeh focuses on the use of medical twins in linking the real and simulated worlds, particularly in cancer diagnosis and treatment. Pronaya Bhattacharya introduces the concept of Healthcare 5.0, integrating the metaverse with AI, blockchain, and ambient tracking for personalized care. Kunal Bhugaonkar discusses the role of cloud computing, AI, and AR/VR in the metaverse’s potential within the medical industry. Joe Iwanaga surveys knowledge of metaverse applications in anatomy education, revealing low familiarity and its potential uses. Dawei Yang combines the metaverse with the medical internet of things (MIoT) for intelligent processing of medical information.',\n",
              " 'Other experts also explore similar themes. Donghua Chen addresses multimodal medical information standards and telemedicine, focusing on patient privacy and technological challenges. Ahmad Musamih emphasizes the metaverse’s high potential in healthcare, particularly in telemedicine and wellness. Mengting Sun explores the potential for digital medicine and chronic disease management through AI in the metaverse. Ioannis Skalidis examines the acceleration of telemedicine in cardiovascular health with metaverse integration, highlighting new opportunities, while Quirino Piacevoli explains how metaverse-driven digitalization is reducing treatment costs and creating cost-efficient models in healthcare.',\n",
              " 'Cinay Dilibal investigates the role of augmented reality in healthcare, specifically highlighting concerns about patient identity security, which can be addressed using blockchain. Ashraf Kanan demonstrates how AR technology can positively impact healthcare education for students with special needs, improving their learning experiences. In the artistic realm, Ying Guo explores the aesthetic potential of the metaverse by transforming 2D images into 3D to enhance art appreciation.',\n",
              " 'Additionally, Mahfuzulhoq Chowdhury introduces a framework for integrating Web 2.0, Web 3.0, and metaverse task execution in 6G networks, promoting efficient task coordination. Arti Yadav performs a systematic analysis of 72 articles, showing the positive impact of augmented',\n",
              " \"reality on academic performance and motivation. Mohd Faiz Mohd Yaakob discusses the innovative use of augmented reality in postgraduate education, demonstrating its effectiveness in improving understanding of educational law. Rommel M.A. Al Ali examines the influence of motivation and metacognition in distance learning, and Kriti Priya Gupta explores the factors that affect teachers' willingness to adopt VR in management education.\",\n",
              " 'Thomason’s (2021) comprehensive study explores the metaverse’s potential across various sectors of the healthcare industry. Thomason identifies education and wellness as key areas where the metaverse can play a transformative role. She emphasises the collaborative potential of the metaverse in healthcare work, utilising virtual spaces. Moreover, Thomason delves into the application of augmented reality (AR) and virtual reality (VR) for medical education and clinical care. By addressing these critical aspects, Thomason underscores the metaverse’s capacity to revolutionise traditional healthcare practices.',\n",
              " 'Bhattacharya et al. (2022) contribute valuable insights by focusing on the challenges faced by rural hospitals in India. Their study acknowledges issues such as limited access to medical equipment and a shortage of experienced doctors. To counter these challenges, the researchers propose innovative solutions through the integration of the metaverse with AR, VR, and blockchain. This collaborative approach aims to bridge the gap between larger hospitals and smaller, more remote healthcare facilities. By fostering shared expertise, Bhattacharya et al. present a holistic vision for improving healthcare in underserved areas.',\n",
              " 'Wang et al. (2022) contribute a unique perspective by proposing the development of a specialised metaverse called medical technology and artificial intelligence (‘meTAI’). This metaverse is specifically designed to focus on medical imaging and guided diagnosis. The researchers outline various applications of meTAI, such as raw data sharing, augmented regulatory science, and virtual comparative scanning. The study not only explores the potential benefits but also addresses challenges associated with implementing meTAI in the healthcare sector.',\n",
              " 'Song and Qin (2022) introduce the concept of metaverse-based healthcare, utilising technologies like AR, VR, and digital twins. The article sheds light on the use of digital twins for observing symptoms and maintaining personal health records. To address the complexities of healthcare data, Song and Qin propose a layered structure model for the digital twin. This model includes real-time monitoring of vitals, decision-making support, and predictive analysis. The researchers acknowledge challenges such as continuous data synchronisation, data encryption, and secure data storage.',\n",
              " 'Zeng et al. (2022) focus on the metaverse’s potential to transform cancer care through AI technology. The study highlights applications such as telemedicine and health education that can contribute to the revitalisation of cancer care. However, the researchers caution that careful considerations are required to address ethical and legal challenges, including data security. The article concludes by emphasising the need for thoughtful implementation to harness the full potential of the metaverse in cancer care.',\n",
              " 'Cerasa et al. (2022) explore the intersection of the metaverse and mental health, specifically addressing disorders such as body dysmorphic disorders, eating disorders, and autism spectrum disorder. The study suggests that metaverse technologies, including personalised treatment and integration of interoceptive technologies, can offer solutions in mental health. However, the researchers highlight potential pitfalls, including the exacerbation of mental illnesses, validation of AI algorithms, data security, and the realism of digital avatars.',\n",
              " 'Ganapathy (2022) provides a simplified overview of the application of the metaverse in healthcare, discussing both its advantages and disadvantages in the clinical sector. The article sheds light on potential limitations in the practical implementation of the metaverse in clinical practice. By presenting a balanced view, Ganapathy contributes to the ongoing discussion on the benefits and challenges associated with integrating the metaverse into healthcare practices.',\n",
              " 'Wu and Ho (2023) explore the metaverse environment in acute medical scenarios, emphasising the use of augmented reality and virtual reality in clinical training for emergency medicine. The study underscores the potential applications of these technologies in enhancing medical education and preparing healthcare professionals for critical situations. By focusing on acute medical scenarios, Wu and Ho contribute valuable insights to the broader discussion on metaverse applications in healthcare training.',\n",
              " 'Dwivedi et al. (2022) discuss the massive potential of the metaverse that extends to the physical world through augmented and virtual reality tools. The researchers propose a future research agenda for the exploration of the metaverse’s impact. Dwivedi et al. highlight the need for further investigation into the vast possibilities offered by the metaverse, including its integration with emerging technologies like cloud computing, robotics, artificial intelligence (AI), augmented reality (AR), virtual reality (VR), and Web 3.0. Wiederhold (2022) provides an insightful overview of what the metaverse is and expresses its widespread impact on the world, particularly in the healthcare sector. By offering a broader perspective, Wiederhold contributes to the understanding of the metaverse’s implications for healthcare. The article serves as a foundational piece in the discourse on the transformative potential of the metaverse in various aspects of healthcare.',\n",
              " 'Moztarzadeh et al. (2023) highlight the use of medical twins to help connect the real world to the simulated world. The researchers focus on the application of machine learning techniques to create reliable digital twins for the cure of cancer and its diagnosis. By emphasising the role of medical twins, Moztarzadeh et al. contribute to the ongoing efforts to enhance diagnostic capabilities through advanced technologies within the metaverse.',\n",
              " 'Bhattacharya et al. (2022a) introduce Healthcare 5.0, which aims to improve healthcare experiences via the metaverse. The proposed framework incorporates ambient tracking, emotive telemedicine, and personalised care. By leveraging blockchain and AI, the researchers emphasise the importance of safeguarding and building trust in healthcare information. Bhattacharya et al. contribute to discussions on the evolving paradigms of healthcare and the',\n",
              " 'role of the metaverse in enhancing patient experiences.',\n",
              " 'Bhugaonkar et al. (2022) provide a glimpse into what the metaverse is and how it provides a platform for interaction between the real world and virtual world. The study concludes by stating how there is significant potential in the metaverse and how the medical industry can flourish by integrating the metaverse with cloud computing, robotics, AI, AR/VR, and Web 3.0. By addressing the intersection of the metaverse with a range of emerging technologies, Bhugaonkar et al. contribute to discussions on the holistic integration of these advancements into healthcare practices.',\n",
              " 'Iwanaga et al. (2022) provide a survey that shows that only 9.4% of respondents are familiar with the metaverse in teaching anatomy. The study highlights the gap in knowledge and usage of the metaverse in anatomy education. Moving forward, the paper emphasises the need for increased awareness and utilisation of the metaverse in teaching anatomy. By shedding light on the current state of knowledge and usage, Iwanaga et al. contribute to discussions on the educational applications of the metaverse.',\n",
              " 'Yang et al. (2022) introduce the integration of the metaverse with the medical internet of things (MIoT). This integration provides intelligent processing of medical information. The researchers highlight how real cloud experts can interact with terminal doctors and users for medical education and consultation using the metaverse. By focusing on the convergence of the metaverse with the medical IoT, Yang et al. contribute to discussions on the interconnectedness of advanced technologies in healthcare.',\n",
              " 'Chen and Zhang (2022) focus on multimodal medical information standards, telemedicine, and medical AI. The article emphasises the challenges associated with technology and patient privacy protection. By addressing critical issues, such as standards and privacy concerns, Chen and Zhang contribute to the ongoing dialogue on the responsible implementation of the metaverse in healthcare.',\n",
              " 'Musamih et al. (2022) discuss the high potential of the metaverse in healthcare by utilising virtual, digital, and 3D environments. The researchers explore the wide application of the metaverse, including telemedicine, marketing, wellness, etc. Musamih et al. contribute to discussions on the diverse ways in which the metaverse can impact and enhance various facets of the healthcare ecosystem.',\n",
              " 'Sun et al. (2022) explore the potential of the metaverse in digital medicine, with a focus on chronic disease management such as chronic obstructive pulmonary disease (COPD) and obstructive sleep apnoea-hypopnoea syndrome (OSAHS). The article discusses how the metaverse, infused with AI, can tackle various healthcare-related challenges. Sun et al. contribute to discussions on the role of the metaverse in personalised and digitally-driven approaches to managing chronic diseases.',\n",
              " 'Skalidis et al. (2022) discuss how the pandemic accelerated the adoption of telemedicine in',\n",
              " 'cardiovascular health and increased the advancement of the metaverse. The article introduces CardioVerse, an integration of the metaverse with cardiovascular medicine, offering high opportunities for disease analysis and education. Skalidis et al. contribute to discussions on the rapid changes in healthcare delivery models and the potential synergies between telemedicine and the metaverse.',\n",
              " 'Piacevoli and Piacentini (2023) state how the rapid progress in digitalisation has given room for the growth of healthcare and medicine. The article highlights the creation of cost-efficient models and the reduced cost of treatment. Piacevoli and Piacentini contribute to discussions on the broader implications of digitalisation for healthcare, emphasising the potential for more accessible and affordable healthcare services.',\n",
              " 'Dilibal and Tur (2022) state how the metaverse enables augmented reality-assisted health using wearable biomedical devices and AI. The article discusses the advantages of incorporating augmented reality in health applications. However, Dilibal and Tur also address concerns regarding the security of patient identities and data, emphasising the need for proper addressing using technologies like blockchain. By considering both the benefits and challenges, Dilibal and Turcontribute to discussions on the responsible integration of the metaverse in healthcare.',\n",
              " 'Kanan et al. (2023) present a study that investigates the impact of AR technology on the learning experiences of students with special needs. The findings demonstrate significantly enhanced learning experiences in the AR group compared to the control group. Kanan et al. showcase the potential of augmented reality to enrich educational experiences, particularly for students with special needs. The study contributes to discussions on the inclusive applications of advanced technologies in education.',\n",
              " 'Guo (2023) explores the metaverse concept by employing an aesthetic approach to art appreciation. Specifically, Guo focuses on transforming 2D images into 3D using a novel block distance calculation method. The proposed method enhances virtual viewpoint rendering, leading to significantly improved image quality. Guo’s work contributes to the broader understanding of how the metaverse can be harnessed for creative and aesthetic purposes, extending beyond traditional applications.',\n",
              " 'Chowdhury (2023) introduces a ground-breaking framework for Web 2.0, Web 3.0, and metaverse task execution in 6G immersive networks. The proposed intelligent scheme achieves a notable reduction in delay and a substantial increase in utility gain compared to benchmark schemes. Chowdhury’s work addresses the need for a unified resource slicing and task service coordination model, offering a comprehensive solution for efficient and coordinated task execution across diverse web generations.',\n",
              " 'Yadav and Gupta (2023) comprehensively analyses AR’s role in education through a systematic literature review of 72 research articles published in esteemed journals spanning the decade from 2010 to 2020. The investigation aims to elucidate the current landscape of AR technology in education by examining its advantages, applications across diverse educational',\n",
              " 'disciplines, global prevalence, utilised tools and technologies, and its overall impact on the learning environment. The results underscore positive outcomes, including enhanced academic performance, heightened student motivation and engagement, increased effectiveness, and a favourable attitude towards technology-driven learning. The analysis reveals that the application of AR varies across disciplines based on technological involvement and the specific needs of each field. Despite being in its nascent stage, the study concludes that AR holds significant potential to revolutionise the teaching-learning paradigm.',\n",
              " 'Yaakob et al. (2021) aim to elevate the instructional quality for postgraduate students, acknowledging the need for a more sophisticated approach compared to undergraduate and diploma levels. Recognising the imperative for continuous improvement, educators delve into researching teaching weaknesses. The specific focus here is on enhancing postgraduate students’ comprehension of the educational law course through the innovative integration of AR. Employing action research methods, the study demonstrates a tangible improvement in students’ understanding following the intervention. The implications of these findings extend to informing academic development in education and offering valuable insights for policymakers to refine education policies.',\n",
              " 'Al Ali and Saleh (2023) address the global proliferation of distance learning systems, prompting countries to assess their efficiency. Central to these systems are factors such as motivation and a commitment to research in metacognition among learners. The research aims to gauge the predictive influence of these elements on the efficiency of distance learning, employing the development of two scales for measurement. Employing a quantitative survey approach, the study establishes and validates the psychometric properties of the developed scales. Results indicate a significant impact of motivation and passion for metacognition on the effectiveness of distance education. Moreover, a robust and reciprocal influence relationship between motivation and metacognition passion is affirmed. Statistically significant differences are identified in student responses, favouring the gifted, third-year students, and those with higher achievement scores. Conversely, no significant variations emerge based on gender, academic branch, or the learning platforms utilised by students. These findings contribute valuable insights to the ongoing discourse on optimising distance learning systems.',\n",
              " 'Gupta and Bhaskar (2022) delves into the determinants of teachers’ willingness to embrace VR applications in the context of Indian business schools, with a specific focus on the ‘management’ discipline within higher education. Employing a cross-sectional design, the research examines the perspectives of 508 teachers from 50 B-schools in the National Capital Region of Delhi, India. The empirical model, tested through exploratory factor analysis and multiple regression analysis, reveals key insights. Notably, teachers’ technology-related personal characteristics, including computer expertise, computer self-efficacy, and personal innovativeness, alongside personality traits such as extraversion, conscientiousness, and openness to experience, along with demographic factors like age, significantly influence teachers’ intentions regarding the adoption of VR technology in the realm of management education. These findings provide valuable insights into the intricate interplay of personal dispositional factors shaping the acceptance of VR applications among educators in the Indian',\n",
              " 'higher education landscape.',\n",
              " 'In summary, the diverse array of studies discussed here collectively paints a vivid picture of the evolving landscape of the metaverse’s role in the healthcare industry. From addressing challenges in rural healthcare to proposing specialised metaverse environments for medical imaging, these studies provide valuable insights into the potential benefits and challenges associated with integrating the metaverse into healthcare practices. The varied applications, including mental health, cancer care, and chronic disease management, underscore the versatility of the metaverse in addressing complex healthcare needs. As technology continues to advance, these studies pave the way for a more nuanced understanding of how the metaverse can shape the future of healthcare delivery and education.',\n",
              " 'This paper implements various techniques that aim to create a healthcare bubble within the metaverse, potentially transforming millions of lives by offering innovative healthcare solutions. However, to fully realize this vision, several significant gaps must be addressed. First and foremost, the current lack of an exceptionally high-speed network infrastructure is a major hindrance. The metaverse demands immense data processing and real-time interaction capabilities, which the existing internet infrastructure cannot adequately support. Without a robust, high-speed network, seamless connectivity and the immersive experience required for healthcare in the metaverse remain out of reach.',\n",
              " 'Another critical gap is the prohibitive cost of VR equipment, which limits access to metaverse healthcare solutions. VR devices and supporting technologies are expensive, preventing broader adoption by both healthcare providers and patients. This creates a financial barrier that must be overcome for the metaverse to expand into mainstream healthcare.',\n",
              " 'Moreover, delays in diagnosis within the metaverse pose a serious risk to patient outcomes, with increased mortality rates as a potential consequence. Timely diagnosis and intervention are crucial in healthcare, and any lag in virtual healthcare systems could have life- threatening consequences. Additionally, the metaverse currently lacks an environment that can effectively monitor and analyse post-surgery complications. The absence of such tools prevents continuous patient monitoring and post-operative care, which are essential for identifying and addressing complications early on.',\n",
              " 'For the metaverse to truly revolutionize healthcare, these issues—network infrastructure, affordability of technology, timely diagnosis, and post-surgery complication management—must be thoroughly addressed.',\n",
              " 'The concept of implementing healthcare solutions within the metaverse represents a groundbreaking transformation in the way medical services are delivered, offering potential to significantly improve healthcare accessibility, efficiency, and outcomes for millions of individuals. By creating a virtual healthcare ecosystem, the metaverse could enable seamless',\n",
              " \"interactions between patients, healthcare providers, and technology-driven tools, fostering an innovative platform for diagnosis, treatment, monitoring, and preventive care. However, the realization of such a vision faces numerous substantial challenges that must be meticulously addressed to unlock its full potential. Among these challenges, the inadequacies in current network infrastructure, the prohibitive costs of required technologies, risks associated with delays in virtual healthcare delivery, and the lack of robust post-operative monitoring systems stand out as critical barriers. These gaps not only hinder the metaverse's capacity to deliver reliable healthcare solutions but also raise ethical, logistical, and financial concerns that need careful consideration.\",\n",
              " 'One of the foremost challenges in integrating healthcare into the metaverse lies in the current limitations of global network infrastructure. The metaverse, as envisioned, relies on vast amounts of data to enable immersive, real-time interactions between users and systems. These interactions require ultra-high-speed internet connections with minimal latency to ensure smooth communication and an uninterrupted experience. Unfortunately, the present state of internet infrastructure in many parts of the world is ill-equipped to meet these demands. Despite advancements in fiber-optic technology, 5G networks, and satellite internet systems, a significant portion of the global population still lacks access to high-speed connectivity. Even in technologically advanced regions, network bottlenecks, inconsistent speeds, and latency issues pose significant challenges. For healthcare applications, which demand exceptional precision and reliability, these limitations become particularly critical. A minor delay in transmitting data or rendering graphics in a virtual environment can result in diagnostic inaccuracies, miscommunication, or failure to provide timely interventions. This dependency on high-speed networks not only restricts the metaverse’s ability to function effectively but also exacerbates disparities in healthcare access, leaving underserved and rural populations at an even greater disadvantage. To overcome this, a global effort to upgrade and expand network infrastructure is essential. Governments, technology providers, and healthcare organizations must collaborate to accelerate the deployment of advanced internet technologies, ensuring equitable access to the high-speed networks required to support metaverse-driven healthcare solutions.',\n",
              " 'Another major obstacle is the prohibitive cost of virtual reality (VR) equipment and supporting technologies, which serves as a substantial barrier to entry for both healthcare providers and patients. VR headsets, haptic devices, augmented reality (AR) systems, and the computational hardware required to power these tools remain prohibitively expensive for most individuals and organizations. Healthcare providers face significant financial constraints in adopting these technologies at scale, particularly smaller clinics and hospitals operating with limited budgets. For patients, the cost of acquiring VR devices for personal use further limits accessibility to metaverse healthcare services. This financial barrier not only slows the adoption of the metaverse in healthcare but also risks creating a system where only wealthier institutions and individuals can benefit from its innovations. To address this issue, a multipronged approach is required. Governments and private organizations could offer subsidies, grants, or incentives to healthcare institutions investing in metaverse technologies. At the same time, technology companies must prioritize research and development aimed at reducing production costs for VR devices, making them more affordable and accessible.',\n",
              " 'Scaling manufacturing processes, leveraging economies of scale, and exploring alternative materials could all contribute to lowering costs. Additionally, developing lower-cost alternatives to existing VR systems, such as smartphone-compatible VR devices or web-based AR applications, could help bridge the gap for populations with limited financial resources.',\n",
              " 'The issue of delays in diagnosis and intervention within metaverse healthcare systems raises significant concerns regarding patient safety and outcomes. Timely diagnosis is a cornerstone of effective healthcare, as early detection of medical conditions often determines the success of subsequent treatments. In the metaverse, where diagnosis relies heavily on virtual tools, simulations, and data processing, any lag in these processes can have dire consequences. For example, a delay in identifying the symptoms of a heart attack, stroke, or sepsis could result in irreversible damage or death. The risk of diagnostic delays is heightened by the complexity of integrating AI-driven tools, medical databases, and real-time patient data within a virtual environment. AI systems must be trained and calibrated to operate seamlessly within the metaverse, accounting for factors such as diverse patient demographics, variable health conditions, and environmental influences. Moreover, these systems must be designed to detect and rectify errors autonomously to ensure reliable and prompt diagnostic outcomes. Addressing this challenge requires significant investment in research and development to refine the algorithms and data-processing capabilities that underpin virtual diagnostic tools. Collaborative efforts between healthcare professionals, technologists, and regulatory bodies are essential to create standards and protocols that ensure the accuracy, speed, and safety of metaverse-based diagnostic systems.',\n",
              " 'Equally concerning is the lack of comprehensive tools and systems within the',\n",
              " 'metaverse to monitor and manage post-surgery complications. Post-operative care is a critical phase of the patient journey, requiring vigilant monitoring to identify and address complications such as infections, blood clots, or organ dysfunction. In traditional healthcare settings, this involves regular follow-up visits, diagnostic tests, and real-time communication between patients and healthcare providers. The absence of similar capabilities in the metaverse significantly limits its utility as a comprehensive healthcare platform. While some wearable devices and remote monitoring technologies have made strides in capturing real-time patient data, these solutions are not fully integrated into the metaverse. Furthermore, the virtual environment lacks sophisticated tools to analyze post-surgery data and provide actionable insights to healthcare providers. Without these capabilities, the metaverse cannot offer the level of continuity and reliability required for effective post-operative care. To address this gap, investments in wearable technologies, sensors, and AI-driven analytics must be prioritized. These tools should be seamlessly integrated into the metaverse, enabling continuous monitoring of vital signs, wound healing, and other critical indicators. Additionally, the development of virtual care teams—comprising AI algorithms and human clinicians—could enhance the metaverse’s ability to deliver proactive and personalized post-operative care.',\n",
              " 'Ultimately, while the healthcare metaverse holds immense potential to revolutionize medical services and improve lives, realizing this vision requires addressing several foundational challenges. Network infrastructure must be upgraded to provide the high-speed,',\n",
              " 'low-latency connectivity essential for immersive and reliable virtual interactions. The cost of VR and related technologies must be reduced to ensure widespread access and equitable adoption. Diagnostic tools within the metaverse must be optimized for speed, accuracy, and reliability to prevent delays that could endanger patient lives. Finally, robust systems for post- surgery monitoring and care must be developed to ensure continuity and safety throughout the patient journey. Overcoming these challenges will require unprecedented collaboration between governments, healthcare providers, technology companies, and research institutions. By addressing these gaps, the healthcare metaverse can fulfill its promise of transforming millions of lives through innovative, accessible, and effective medical solutions.',\n",
              " 'The primary challenge this project seeks to address is the integration of healthcare into the metaverse, which is currently hindered by several interconnected issues. First, the absence of a high-speed, reliable network infrastructure makes it difficult to support the data transmission demands of real-time healthcare services, where delays can directly impact patient outcomes. Additionally, the high cost of VR equipment presents a significant barrier to accessibility, limiting the potential reach of metaverse-based healthcare solutions. Furthermore, delays in diagnosis, often exacerbated by these technological limitations, contribute to higher mortality rates, and there is no current environment for effectively analyzing post-surgery complications within the metaverse. Overcoming these barriers is essential to creating a seamless, accessible, and effective healthcare system in the virtual world.',\n",
              " \"The primary challenge that this project aims to tackle is the seamless integration of healthcare into the metaverse, which, as of now, is obstructed by a series of complex, multifaceted issues that need to be resolved before the full potential of the metaverse in healthcare can be realized. These issues are not isolated but are intricately interwoven, each presenting unique obstacles that require a concerted effort to overcome. First and foremost, one of the most pressing and fundamental barriers lies in the lack of a high-speed, reliable, and highly efficient network infrastructure capable of meeting the immense and growing data transmission demands of real- time healthcare services. The metaverse, by its very nature, requires the uninterrupted exchange of massive amounts of data, which includes, but is not limited to, patient medical records, diagnostic imagery, real-time health monitoring data, and video consultations between patients and healthcare professionals. Each of these data streams needs to be transmitted instantly, without delays, lags, or disruptions, as any breakdown in this communication can severely undermine the effectiveness of healthcare delivery, potentially jeopardizing patient safety and treatment outcomes. In a healthcare environment, where every second matters and the timely administration of medical care can mean the difference between life and death, delays are simply unacceptable. For instance, if there is a delay in transmitting a patient's vital signs to the attending physician or if the doctor's ability to access and review critical diagnostic information is impeded due to network issues, it can result in delayed diagnosis, delayed treatment, or even catastrophic outcomes for the patient.\",\n",
              " \"To meet these demands, the metaverse requires an ultra-high-speed, low-latency, and highly secure internet infrastructure. The current state of the global network infrastructure, with its frequent interruptions, data bottlenecks, and inadequate bandwidth in certain regions, simply cannot support the real-time data transmission requirements needed to run a fully functional metaverse-based healthcare system. It’s not just about speed—it's also about reliability and the ability to support simultaneous connections from multiple users (patients, doctors, medical specialists, healthcare administrators, and more) all accessing and interacting with real-time medical data. Without a robust, dependable network backbone that guarantees consistent high- quality connections, the seamless healthcare experiences that the metaverse promises will remain out of reach. Thus, the establishment of a next-generation network infrastructure capable of supporting the healthcare demands of the metaverse is paramount. This network infrastructure needs to be scalable, able to accommodate an ever-growing amount of data as the metaverse expands, and highly secure to safeguard sensitive patient information and ensure privacy compliance with global healthcare regulations.\",\n",
              " 'In addition to these network limitations, the high cost of virtual reality (VR) and augmented reality (AR) equipment presents another formidable barrier to the widespread adoption and accessibility of metaverse-based healthcare solutions. Although VR and AR technologies have advanced considerably in recent years, they still remain prohibitively expensive for many healthcare providers, particularly smaller practices, clinics, and healthcare institutions in underfunded regions or countries. The devices required to access the metaverse—such as high- end VR headsets, haptic feedback systems, motion sensors, and advanced medical tools—are not only costly to purchase but also require ongoing maintenance, upgrades, and specialized technical support. For individual patients, particularly those without insurance coverage or who are living in lower-income areas, the cost of purchasing or even renting the necessary VR equipment is often a significant financial burden. The price of this equipment limits access to essential virtual healthcare services, thereby excluding a large portion of the population from benefitting from the convenience, accessibility, and efficiency that the metaverse can offer.',\n",
              " 'In parallel, healthcare institutions face challenges related to justifying the financial investment needed to implement these technologies on a large scale. The integration of the metaverse into healthcare settings requires substantial financial resources, including not only the initial cost of equipment but also the operational costs associated with maintaining and upgrading the technology infrastructure, training medical professionals to use the new systems, and ensuring the security of the platforms. These costs, when combined with already strained healthcare budgets, may deter healthcare providers from embracing these technologies, particularly in countries or regions with limited resources. If VR and AR technologies remain out of reach for most healthcare providers and patients, the full potential of metaverse-based healthcare will remain unrealized, keeping this promising innovation confined to the realm of the privileged few.',\n",
              " 'Furthermore, delays in diagnosis within the metaverse pose a grave risk to patient outcomes, contributing to higher mortality rates and worsening the overall quality of healthcare delivery. In traditional healthcare settings, delays in diagnosis can have life-threatening consequences, particularly for patients suffering from critical conditions such as heart attacks, strokes, sepsis,',\n",
              " \"and cancer. In the metaverse, such delays can be exacerbated by technological limitations, such as slow processing of diagnostic data, bottlenecks in the transmission of medical images, or lags in video consultations. For instance, if a doctor is unable to promptly access a patient's radiological images or diagnostic tests due to delays in the data transmission process, the time it takes for the doctor to make an informed decision regarding the patient's treatment could be lengthened, leading to missed opportunities for timely intervention. As a result, patients may face a higher risk of morbidity and mortality due to the inability to quickly identify and treat their conditions. In the case of chronic conditions or rapidly progressing diseases, the consequences of these delays are particularly devastating.\",\n",
              " 'For the metaverse to be a viable platform for healthcare delivery, addressing the issue of delays in diagnosis is essential. Healthcare providers must be able to access real-time diagnostic data, communicate with patients and other healthcare professionals without interruption, and make immediate decisions regarding treatment plans. To accomplish this, both the metaverse’s underlying technology and the healthcare infrastructure it relies on must be optimized to eliminate latency, streamline data processing, and ensure the rapid transmission of crucial medical information.',\n",
              " \"Additionally, the lack of an effective virtual environment within the metaverse to monitor and analyze post-surgery complications presents another critical issue. Post-operative care is essential to the recovery process, as complications can arise in the days and weeks following surgery, sometimes even in patients who initially appeared to be recovering well. Common post-surgery complications such as infections, blood clots, organ rejection, and adverse reactions to anesthesia require close monitoring and timely intervention. In a traditional healthcare setting, doctors and nurses are able to closely observe patients and administer appropriate care. However, in the virtual environment of the metaverse, there is currently no adequate system for tracking patients' recovery in real-time or assessing emerging complications. The inability to effectively monitor a patient's recovery in the virtual space could prevent healthcare providers from detecting early signs of complications, leading to worsened outcomes and an increased risk of patient harm. To overcome this limitation, the metaverse needs to incorporate real-time monitoring tools, such as sensors that can detect changes in vital signs, body temperature, or other indicators of potential complications. Additionally, remote diagnostic tools must be developed that allow healthcare professionals to evaluate a patient's post-surgical recovery and intervene when necessary.\",\n",
              " 'Overcoming these barriers—whether they are related to technological infrastructure, equipment affordability, diagnostic delays, or post-operative monitoring—will be crucial for the realization of a fully functional, efficient, and effective healthcare system in the metaverse. Each of these issues presents a major challenge that must be addressed before the metaverse can fulfill its potential as a transformative force in healthcare. However, addressing these challenges is not only necessary but also feasible. With ongoing research, technological advancements, and a concerted effort to make metaverse-based healthcare accessible and effective for all, the future of healthcare could be transformed into a more flexible, scalable, and equitable system. The development of these solutions will pave the way for a healthcare model that is faster, more personalized, and more accessible than ever before, offering benefits',\n",
              " 'to patients and healthcare providers alike, and ultimately changing the way healthcare is delivered across the globe.',\n",
              " \"The primary challenge that this project aims to tackle is the seamless integration of healthcare into the metaverse, which, at present, is hindered by a variety of significant and interconnected issues that need to be addressed before such a transformation can occur. First and foremost, one of the most pressing obstacles is the lack of a high-speed, reliable network infrastructure capable of supporting the immense data transmission requirements necessary for real-time healthcare services. In a metaverse-based healthcare environment, the exchange of medical data, such as patient records, diagnostic images, and real-time monitoring of vitals, needs to occur instantaneously and without interruption. Any delays or disruptions in this data flow could have dire consequences, especially in critical situations where immediate medical attention is required. The network infrastructure must be capable of supporting seamless, high- bandwidth interactions between healthcare professionals and patients, ensuring that consultations, diagnoses, and treatments can be administered in a timely and efficient manner. However, the existing internet infrastructure, which is often plagued by speed limitations, data latency, and frequent connectivity issues, is simply inadequate to support these demands. Until a robust, ultra-high-speed network is established, the metaverse's potential to provide real-time, life-saving healthcare will remain restricted, creating a major barrier to its successful implementation.\",\n",
              " 'In addition to the challenges posed by inadequate network infrastructure, the high cost of virtual reality (VR) equipment represents another significant hurdle to the widespread adoption of metaverse-based healthcare solutions. While VR technology has advanced in recent years, the devices required to fully engage with the metaverse, such as VR headsets, haptic feedback systems, and specialized medical tools, are still prohibitively expensive for many individuals and healthcare providers. This high cost creates a substantial financial barrier, preventing the broad integration of VR-based healthcare solutions into mainstream medical practices. For individual patients, the cost of acquiring the necessary equipment may be out of reach, especially for those who lack insurance coverage or live in areas with limited financial resources. Similarly, healthcare institutions may struggle to justify the financial investment required to implement these technologies on a large scale, especially when considering the costs of maintaining and upgrading the infrastructure necessary to support them. Without making VR technology more affordable and accessible, the metaverse will struggle to realize its full potential in transforming healthcare delivery, as it will remain out of reach for a significant portion of the population.',\n",
              " 'Compounding these issues are the delays in diagnosis that can occur within the metaverse, a problem that is largely driven by both the technological limitations and the potential for network disruptions. In healthcare, time is often the most critical factor, and any delay in diagnosing or treating a condition can have devastating consequences for patient outcomes. For example, when dealing with acute medical conditions such as strokes, heart attacks, or cancer, the speed with which a diagnosis is made and treatment is initiated can determine whether the patient survives or suffers long-term disability. Unfortunately, the technological delays inherent in metaverse healthcare platforms—whether due to lagging network speeds,',\n",
              " 'data bottlenecks, or the slow processing of diagnostic algorithms—can lead to critical delays in providing timely diagnoses. These delays, in turn, contribute to higher mortality rates and poorer health outcomes, undermining the very purpose of virtual healthcare solutions. To effectively use the metaverse for healthcare, it is imperative that these delays are minimized through the development of faster, more efficient diagnostic tools and the establishment of a network infrastructure that can support the immediate transfer of medical data in real-time.',\n",
              " \"Moreover, another crucial gap that must be addressed is the lack of an effective environment within the metaverse for monitoring and analyzing post-surgery complications. Post-operative care is a critical component of the medical process, as complications arising after surgery can often be more dangerous and difficult to manage than the initial procedure itself. In the physical world, healthcare providers are able to monitor patients closely during their recovery, using tools such as in-person checkups, diagnostic tests, and follow-up appointments to detect complications early. However, in the virtual metaverse, there is currently no adequate environment in which healthcare providers can monitor patients' recovery in real time or effectively assess the emergence of complications like infections, blood clots, or organ rejection. The inability to track these complications within the virtual realm means that patients may not receive the timely interventions they need, increasing the likelihood of serious health problems that could have been prevented with proper monitoring. Additionally, healthcare professionals would be at a disadvantage without the tools and systems required to evaluate recovery remotely, limiting their ability to provide continuous, quality care for patients who are recovering from surgery.\",\n",
              " 'Addressing these interconnected challenges is absolutely crucial in order to create a metaverse- based healthcare system that is seamless, accessible, and effective. The integration of healthcare into the metaverse has the potential to dramatically improve access to medical services, enhance patient outcomes, and reduce the burden on healthcare systems worldwide. However, the current technological, financial, and operational barriers must be overcome to fully realize this potential. Efforts must be focused on developing the high-speed, low-latency network infrastructure necessary to support real-time medical interactions, making VR technologies more affordable and accessible to a wider population, and creating effective systems for diagnosing and monitoring patient health in the virtual space. Only when these obstacles are addressed will the metaverse be able to fulfill its promise as a transformative platform for healthcare, offering more personalized, efficient, and equitable care to patients across the globe. Until then, these challenges will remain significant impediments to the widespread adoption of metaverse-based healthcare solutions, preventing the realization of a truly digital healthcare future.',\n",
              " '• User Authentication: The system must ensure secure user authentication for access to healthcare services and personalized recommendations.',\n",
              " '• Data Transmission: The platform should facilitate real-time data transmission between healthcare professionals and patients, including vital stats and other health indicators. • Immersive Environment: The metaverse should provide an immersive environment where users can interact with virtual healthcare professionals, digital twins, and other healthcare services.',\n",
              " '• Health Monitoring Integration: Integration of wearables (like smartwatches, fitness trackers) to continuously monitor health metrics such as heart rate, oxygen levels, and physical activity.',\n",
              " '• Medical Consultation: The system should allow for real-time consultations in the virtual space with doctors, including sharing medical data and reports.',\n",
              " 'physical therapy, and mental health exercises within the metaverse.',\n",
              " '• Collaboration with Medical Experts: Allow healthcare professionals to collaborate remotely using virtual 3D models for surgeries, diagnosis, and case reviews.',\n",
              " '• Performance: The platform should support high data throughput (up to 20 Gbps) and low latency (as low as 5 ms) for smooth interaction and real-time healthcare monitoring.',\n",
              " '• Scalability: The system must be able to scale with increased users, handling up to millions of users simultaneously accessing healthcare services in the metaverse.',\n",
              " '• Reliability: The system should offer high availability (99.9%) and consistent reliability during healthcare consultations and monitoring.',\n",
              " '• Compliance: Ensure compliance with healthcare data regulations, to protect patient information.',\n",
              " '• Technology Availability: The project leverages current AR/VR technologies, AI algorithms for patient monitoring, and healthcare data transmission protocols, which are well- documented and in use in modern healthcare.',\n",
              " '• Technical Expertise: Requires experts in metaverse development, healthcare integration, AI, and cybersecurity. Training or hiring will be essential to ensure success.',\n",
              " '• Infrastructure: Needs high-performance servers, AR/VR gear, cloud services for data storage, and a robust communication network to support real-time healthcare services. • Integration: The system must integrate with existing electronic health record (EHR) systems and healthcare management software.',\n",
              " '• Cost-Benefit Analysis: Initial investments for development, servers, AR/VR hardware, and AI models will be high, but long-term cost savings from virtual consultations and reduced healthcare operational costs are significant.',\n",
              " '• Budget: Includes expenses for hardware (servers, VR headsets), software development, cloud storage, AI model deployment, and security measures.',\n",
              " '• Return on Investment (ROI): ROI can be realized through patient subscription models, reduced in-person consultations, and partnerships with hospitals.',\n",
              " 'partnerships with hospitals and insurance companies.',\n",
              " '• User Acceptance: Healthcare professionals and patients need to be familiar with the concept of virtual healthcare, requiring adequate training and demonstrations.',\n",
              " 'metaverse environment and interacting with AI-driven healthcare tools.',\n",
              " 'making must be central, ensuring no biases in virtual healthcare diagnosis.',\n",
              " '• Impact on Workforce: Healthcare professionals will need to adapt to virtual interactions, but their roles remain vital for providing personal and direct care.',\n",
              " 'quality virtual environments',\n",
              " '• Development Environment: Visual Studio, PyCharm, Unity or Unreal Engine for AR/VR development',\n",
              " '• Libraries and Frameworks: TensorFlow/Keras for AI, ARCore for AR integration, OpenCV for health monitoring, Node.js for backend services',\n",
              " '• Security Tools: SSL/TLS for secure data transmission, AES for data encryption, and OAuth for authentication',\n",
              " 'This image shows how the metaverse could change healthcare by allowing patients and doctors to interact in a virtual environment. The patient is in a bed at home, and the doctor is at their desk, but both are connected to a \"Metaverse Bubble\" using virtual reality (VR) headsets. This \"bubble\" represents a shared digital space where they can meet and communicate as if they were in the same room.',\n",
              " 'The cloud and the colorful blocks underneath represent the technology working behind the scenes, such as storing medical data and ensuring that the patient’s information is available to the doctor in real-time. This setup makes it easier for patients to receive care from their doctors, even if they are far apart.',\n",
              " 'In simple terms, the image shows how the metaverse could allow patients and doctors to connect virtually, making healthcare more flexible, accessible, and convenient for everyone.',\n",
              " 'This image serves as a visionary representation of how the metaverse could profoundly reshape the healthcare landscape by providing an innovative platform for patients and doctors to connect, interact, and deliver medical care in a fully virtualized environment. It illustrates a scenario where a patient, who is at home, lying in a bed, is able to engage with their doctor,',\n",
              " 'who is sitting at their desk in a completely different location, through the use of advanced virtual reality (VR) headsets. These headsets enable both the patient and the doctor to enter a shared \"Metaverse Bubble,\" which is a dynamic, immersive digital space that allows them to meet and communicate as if they were in the same physical room, despite being separated by distance. This shared digital environment removes the traditional barriers that have historically limited access to healthcare, such as geographical location, physical mobility, and time constraints, offering a seamless, efficient, and highly engaging way to facilitate healthcare consultations.',\n",
              " 'In this virtual realm, the patient is no longer bound by the limitations of in-person visits, such as the need to travel long distances to see a specialist or the time-consuming process of waiting for an appointment. They can receive medical advice, discuss their symptoms, and undergo diagnostic assessments in real-time, all from the comfort of their own home. For the doctor, the virtual consultation provides an opportunity to interact with the patient in a more personalized and efficient manner, offering medical advice, prescribing treatments, and even performing diagnostic tests or monitoring patient data—all without the logistical challenges of scheduling in-person visits. The immersive nature of the metaverse enables both the patient and the doctor to engage in meaningful, real-time interactions, with the added benefit of visual aids, such as virtual medical charts, 3D imaging, and augmented reality tools, that can enhance the quality and precision of the consultation.',\n",
              " \"The underlying technology that enables this virtual healthcare environment is represented in the image by the cloud and the colorful blocks underneath, which symbolize the sophisticated and powerful infrastructure that supports this advanced system. The cloud is a critical element in the functioning of this metaverse-driven healthcare platform, serving as the secure, centralized hub where patient data, medical histories, and real-time health information are stored and accessed. This cloud infrastructure ensures that all medical data is available to both the doctor and the patient when needed, providing a comprehensive, up-to-date view of the patient's health condition. Doctors can access detailed patient records, review lab results, and make informed decisions about the course of treatment, all within the same digital environment. This capability enables a level of accuracy and speed in diagnosis that would be difficult to achieve through traditional methods, where medical records are often fragmented or delayed in reaching healthcare providers. Additionally, the seamless integration of technology facilitates real-time communication between healthcare professionals, ensuring that the most accurate and relevant information is always accessible during consultations.\",\n",
              " 'The colorful blocks underneath the cloud represent the complex systems of interconnected technologies that work together to ensure that this virtual healthcare ecosystem operates efficiently and effectively. These technologies include advanced algorithms for data processing, AI-driven diagnostic tools, and secure communication networks that facilitate the exchange of medical information. The integration of these systems allows for the smooth transfer of data between devices and ensures that all parties involved in the consultation—from the doctor to the patient, to any additional healthcare professionals or specialists who may be involved—can interact in a synchronized, efficient manner. This real-time sharing of medical data and collaboration between healthcare providers not only enhances the accuracy of',\n",
              " 'diagnoses but also accelerates the delivery of treatment, making healthcare delivery faster, more responsive, and more personalized.',\n",
              " 'The broader implication of this image is the transformative potential of the metaverse in overcoming the traditional barriers to healthcare access. In the past, patients who lived in remote areas, faced physical mobility challenges, or had limited access to medical services had to endure long travel times and significant wait times for appointments in order to receive care. The metaverse has the potential to eliminate these challenges by bringing healthcare directly to patients, wherever they may be. Through the use of VR headsets and other connected devices, patients can interact with their doctors in real-time, just as if they were sitting together in the same room, without the need for physical presence. This virtual approach to healthcare not only improves convenience but also significantly reduces the logistical hurdles associated with traditional healthcare delivery, making it far more accessible to underserved populations, such as the elderly, the disabled, or those living in rural or isolated communities.',\n",
              " 'Moreover, the metaverse-based healthcare environment makes it easier for healthcare providers to reach a larger patient base, allowing them to offer consultations, treatments, and monitoring services without being constrained by the physical limitations of their offices or clinics. Doctors and specialists can virtually \"visit\" multiple patients throughout the day, offering a level of flexibility that traditional healthcare delivery methods cannot match. This could potentially lead to greater efficiency in medical practices, enabling healthcare professionals to manage their time and resources more effectively, and ultimately provide better care to more patients. Additionally, for patients with chronic conditions or those requiring ongoing care, the metaverse offers the possibility of continuous monitoring and follow-up consultations, without the need for frequent trips to a physical healthcare facility.',\n",
              " 'By offering more flexible, scalable, and accessible healthcare options, the metaverse has the potential to democratize medical care, making it more equitable for people of all backgrounds and circumstances. The ability to connect with doctors remotely, receive real-time medical attention, and access comprehensive health information from anywhere in the world could drastically improve the patient experience. The image encapsulates the vision of a future where healthcare is no longer confined to physical locations, but instead becomes a seamless, global network that empowers patients and healthcare providers alike. In this vision, the metaverse represents not just a technological innovation, but a paradigm shift in how we think about healthcare—one that prioritizes accessibility, efficiency, and patient-centered care on a global scale.',\n",
              " 'Ultimately, the metaverse offers the potential to reshape healthcare into a more flexible, efficient, and patient-friendly system, breaking down the barriers that have traditionally limited access to medical care. The image demonstrates how this technology could bring about a new era of healthcare delivery that is more adaptable to the needs of patients and healthcare providers, transforming the patient experience and ensuring that high-quality care is accessible to everyone, regardless of their location or circumstances. Through virtual consultations, real- time data sharing, and immersive experiences, the metaverse has the ability to revolutionize the way healthcare is provided, paving the way for a future where medical care is no longer bound by physical constraints, but instead is a global, interconnected system that offers',\n",
              " 'personalized, immediate, and comprehensive care to all.',\n",
              " 'This image provides a vivid and compelling illustration of how the metaverse could revolutionize the healthcare landscape, offering a new level of accessibility and convenience for both patients and healthcare providers. In this virtual space, a patient who is at home, resting in a bed, is able to connect with their doctor, who is sitting comfortably at their desk in a completely different location. Both individuals are equipped with virtual reality (VR) headsets, which serve as the gateway to an immersive \"Metaverse Bubble.\" This \"bubble\" symbolizes a shared digital space that transcends physical barriers, where the patient and the doctor can meet, interact, and communicate as though they were in the same room, despite being miles apart. The power of this technology lies in its ability to create a sense of presence and immediacy, allowing for real-time conversations, assessments, and medical consultations without the need for either party to be physically present in the same location.',\n",
              " \"The cloud and the colorful blocks depicted in the image play a crucial role in the technology that supports this virtual healthcare system. These elements symbolize the vast and complex infrastructure that operates behind the scenes to ensure the smooth functioning of the metaverse-based healthcare platform. The cloud represents the secure and efficient storage of medical data, such as patient records, diagnostic information, treatment histories, and real-time health updates. This cloud-based storage ensures that the doctor has access to the patient's information at any given moment during their virtual consultation, facilitating accurate diagnoses and timely decision-making. The colorful blocks underneath further emphasize the technological systems that connect different devices, allowing for the seamless transfer of medical data and ensuring that the patient's information is instantly available to the doctor, no matter where they are. This real-time data sharing not only enhances the quality of care but also promotes efficiency, as doctors can access critical health data on demand, without the delays typically associated with physical records or traditional appointment scheduling.\",\n",
              " 'What this image ultimately showcases is the potential for a transformative shift in healthcare delivery, where distance, physical limitations, and time constraints no longer stand as obstacles to accessing quality medical care. By bridging the gap between patients and doctors, the metaverse creates a virtual space that is flexible, adaptable, and highly responsive to the needs of both parties. Patients, particularly those in remote areas or with mobility challenges, can receive expert medical consultations from the comfort of their homes, eliminating the need for long-distance travel, waiting in crowded clinics, or missing out on essential care due to geographical or physical limitations. For doctors, this new approach to healthcare delivery enables them to provide more comprehensive, timely, and personalized care to a wider range of patients, all while working from their offices or homes, without the constraints of traditional office hours or the need for in-person appointments.',\n",
              " 'In this context, the metaverse has the potential to make healthcare more accessible, efficient, and convenient, democratizing medical services by making them available to individuals regardless of where they live or their physical condition. This technology could be especially beneficial for vulnerable populations, such as the elderly, those with chronic illnesses, or individuals living in rural or underserved regions, who often face challenges in accessing timely medical care. With the metaverse, the world of healthcare expands beyond the walls of',\n",
              " 'hospitals and clinics, offering an innovative solution that promotes inclusivity and broadens access to essential services. The image serves as a powerful visual representation of how the metaverse could break down traditional barriers in healthcare, enabling real-time, remote interactions between patients and doctors and paving the way for a more flexible, efficient, and patient-centric healthcare system.',\n",
              " 'The DFD for the Healthcare Metaverse Platform effectively illustrates the interconnectedness of various stakeholders within the healthcare ecosystem. By focusing on enhancing communication, training, and predictive capabilities, this project aims to revolutionize healthcare delivery, making it more efficient, accessible, and effective in addressing patient needs in the metaverse.',\n",
              " 'Key Components',\n",
              " 'Data Flows',\n",
              " 'The Healthcare Metaverse Platform aims to revolutionize healthcare delivery by integrating virtual reality technologies into everyday medical practices. By facilitating seamless interactions between patients, doctors, medical students, and administrators, this platform enhances access to healthcare, improves training for future professionals, and ensures the security of sensitive information. The diagram serves as a foundational overview of how these elements work together to create a comprehensive and innovative healthcare solution.',\n",
              " 'Below is a detailed explanation of each component and its role in the overall ecosystem.',\n",
              " 'Key Stakeholders and Their Functions',\n",
              " 'This methodology establishes a secure, high-speed network framework for healthcare applications in the metaverse, focusing on minimizing latency and enhancing reliability. The proposed network aims for terabit-per-second data transfer rates to ensure uninterrupted communication between patients and medical professionals. The methodology leverages Nyquist’s equation (Equation 1) to calculate the optimal data transmission rate:',\n",
              " 'where AAA is the data rate (bps), BBB is the channel bandwidth, and SNR is the signal-to- noise ratio. In the example, with a 1 GHz bandwidth and a 20 dB SNR, the achievable data rate is approximately 6.65 Gbps.',\n",
              " 'To further optimize network performance, latency is calculated using Equation 2:',\n",
              " 'T=propagation delay+processing delay+transmission',\n",
              " 'Assuming a 1,000 km distance and a channel speed of 100,000 km/s, with 5 ms processing and transmission delays, the total latency is 11 ms.',\n",
              " 'Finally, network reliability, defined as the probability of successful data transmission, is computed as:',\n",
              " 'where FFF represents the transmission failure rate. With a 3% failure rate, reliability is approximately 97%. Comparative analyses (Tables 2 and 3) show that this model offers superior data rates, lower latency, and enhanced reliability over existing frameworks, providing a robust foundation for metaverse-enabled healthcare.',\n",
              " 'This methodology uses statistical analysis and linear regression to determine the optimal pricing strategy for VR headsets, essential for making metaverse technology accessible while maintaining profitability. Initially, a dataset of VR headset prices (price set) and quantities sold ( quantity sold set) is analyzed. Using linear regression, Equation (4) is derived:',\n",
              " 'quantity sold=a×price+b',\n",
              " 'where a=−0.1a = -0.1a=−0.1 and b=100b = 100b=100, indicating that for every 1 USD price increase, sales decrease by 0.1 units. This intercept suggests a theoretical demand of 100 units when price is zero.',\n",
              " 'Revenue is calculated as:',\n",
              " 'revenue=price×quantity sold',\n",
              " 'and maximized by substituting in Equation (4):',\n",
              " 'revenue=price×(−0.1×price+100',\n",
              " \"Differentiating the revenue function with respect to price and setting it to zero yields a critical price point of 1,000 USD. However, this falls outside the dataset's practical range (180–250 USD), so revenue is instead evaluated at endpoint prices. At 180 USD, revenue is 14,760 USD; at 250 USD, it reaches 18,750 USD. Ultimately, an optimal price within the data's\",\n",
              " 'realistic range is chosen at 225 USD, yielding a revenue of 17,437.5 USD, balancing affordability with maximum profitability. Tables 4 and 5 show improved sales and growth using this model over previous strategies.',\n",
              " \"This methodology uses probability-based predictive analysis to assess a patient's likelihood of having either COVID-19 or a common viral infection based on symptoms like fever, cough, and cold. By analyzing data from 300 patients, where 200 were diagnosed with viral infections and 100 with COVID-19, this model leverages Bayes' theorem to predict disease probability for new patients. Bayes' theorem, represented in Equation (7):\",\n",
              " 'enables calculation of probabilities by integrating prior knowledge with observed symptoms. Here, P(Viral) and P(COVID-19) represent initial probabilities based on historical data, with P(Viral)=0.67 and P(COVID-19)=0.34.',\n",
              " 'Given that 150 out of 200 viral cases and 50 out of 100 COVID-19 cases exhibited fever, cough, and cold, the likelihood of having these symptoms for viral and COVID-19 cases, respectively, is calculated as P(Fever, Cough, Cold | Viral)=0.75 and P(Fever, Cough, Cold | COVID-19)=0.5.',\n",
              " \"Applying Bayes' theorem in Equations (8) and (9):\",\n",
              " 'P(Viral | Fever, Cough, Cold)≈0.75×0.670.7=0.717',\n",
              " 'P(COVID-19 | Fever, Cough, Cold)≈0.5×0.340.7=0.2428',\n",
              " 'indicates a higher probability of the patient having a viral infection (0.717) over COVID-19 (0.2428) when presenting these symptoms. This model facilitates early diagnosis, improving patient outcomes by enabling timely treatment. Tables 6, 7, and 8 summarize accuracy comparisons and probability assessments for various medical conditions, showcasing the enhanced reliability of this method for disease prediction.',\n",
              " 'This methodology demonstrates how the metaverse can revolutionize medical training by creating virtual, immersive environments where students can practice complex procedures like laparoscopic cholecystectomy. In this virtual setup, each stage of the surgery involves mathematical concepts and matrix operations, enhancing both precision and learning effectiveness.',\n",
              " 'BP=[120,130,140,110,125]',\n",
              " 'HR=[80,75,90,70,85]',\n",
              " 'SpO2=[98,96,95,99,97]',\n",
              " 'Allergy Assessment: Allergies are tracked in a binary matrix, where 1 denotes the presence of an allergy and 0 indicates absence.',\n",
              " 'Allergy=[0,1,0,0,1]\\\\text{Allergy} = [0, 1, 0, 0, 1]Allergy=[0,1,0,0,1]',\n",
              " 'Weight=[70,80,90,75,85]',\n",
              " 'Dosage Calculation: The dosage of anaesthesia is calculated using a coefficient matrix C=[2,2,2,2,2]C = [2, 2, 2, 2, 2]C=[2,2,2,2,2], following Equation (12):',\n",
              " 'Dosage=C×Weight=[2,2,2,2,2]×[70,80,90,75,85]',\n",
              " 'Dosage=[140,160,180,150,170]=800 (total)',\n",
              " 'Insertion points={(3,5),(7,2),(4,9),(1,6),(8,3)}',\n",
              " 'TrocarPlacementSuccess=[1,0,1,0,1]',\n",
              " 'Landmarks=[′A′,′B′,′C′,′D′,′E′]',\n",
              " 'M=Landmarks×LandmarksTM',\n",
              " 'Instructions=[’Take antibiotics’,’Avoid heavy lifting’,’Apply ice pack’,’Keep the incision cle an’,’Follow up with the doctor’]',\n",
              " 'Repetition=[’Thrice a day for 1 month’,’For 6 months’,’Twice a day for 10 days’,’For 20 day s’,’Every 25 days’]',\n",
              " 'This digital framework facilitates detailed and precise surgical training, allowing students to practice calculations, placements, and post-op care instructions within a simulated, low-risk environment. Through this method, aspiring doctors can gain confidence and competency in surgical procedures before interacting with real patients, thereby bridging theory and practice effectively.',\n",
              " 'Table 3: Sales and rate of growth of this paper’s model',\n",
              " 'Table 4: Comparison of sales between this paper’s model and previous model',\n",
              " 'Table 5: Accuracy of the previous model in accordance with Covid',\n",
              " 'Table 6: Accuracy of this paper’s model in accordance with Covid 19',\n",
              " 'Table 7: Medical Probability/Condition Values',\n",
              " 'Table 8: Anesthesia dosage in mg for the corresponding weight in kg',\n",
              " 'Table 9: Correct prediction of coordinates for Trocar insertion by using Coordinate Geometry',\n",
              " 'Project Objective: To simulate a virtual healthcare environment where users can interact with entities like a virtual doctor and a health monitor, representing how healthcare services might function in a metaverse setting.',\n",
              " 'health advice.',\n",
              " 'After interacting with the entities, users are prompted with an exit message summarizing their activities, such as:',\n",
              " 'This summary helps users feel that their virtual healthcare visit was meaningful and provides closure to the experience.',\n",
              " 'The Healthcare Metaverse Simulation aims to make virtual healthcare services more accessible and interactive. As the healthcare metaverse continues to evolve, this foundational model could be expanded to include real-time consultations, dynamic health monitoring, and immersive VR experiences, bringing healthcare to users’ virtual fingertips.',\n",
              " 'This paper presents a forward-looking perspective on how the metaverse could transform healthcare, offering various possibilities to improve medical services and patient experiences. By prioritizing a fast, secure, and reliable network as a foundational requirement, the metaverse can facilitate seamless virtual healthcare. Furthermore, the paper emphasizes the importance of affordable metaverse equipment',\n",
              " 'to promote widespread access, democratizing the advantages of virtual healthcare services.',\n",
              " 'Key proposed innovations include a predictive model to enable early disease detection and timely treatment, which could significantly reduce mortality rates. Additionally, immersive simulation environments for medical training are suggested to allow healthcare professionals to practice complex procedures, potentially increasing surgical success rates and improving patient outcomes. Virtual consultations emerge as a particularly valuable tool, especially for elderly and paralyzed patients, as they provide a more comprehensive interaction than traditional video calls through augmented and virtual reality. Other potential applications, such as virtual physiotherapy with haptic feedback and mental health interventions, highlight the metaverse’s capacity to make healthcare services more patient-friendly, convenient, and accessible.',\n",
              " 'This paper explores the synergies between the metaverse and healthcare, presenting a vision of enhanced medical services for the future. The methodologies outlined herein aim to provide a comprehensive understanding of the proposed model, contributing insights into the potential advantages of integrating the metaverse into healthcare practices.',\n",
              " 'Firstly, the paper focuses on the primary contributions, emphasising the development of a fast, secure, and reliable network as a foundational element. It also advocates for the affordability of metaverse equipment, ensuring widespread accessibility and democratising the benefits of virtual healthcare experiences. The paper introduces a predictive model designed to reduce mortality rates by enabling early disease detection and timely treatment. Furthermore, it suggests immersive practice environments for medical professionals, potentially improving the success rates of surgeries.',\n",
              " 'These contributions can be further expanded and a study can be made to explore other applications of metaverse. Virtual consultations emerge as a key innovation, offering a distinct advantage for elderly and paralysed patients. This goes beyond traditional video calls by utilising augmented and virtual reality technologies, providing doctors with a virtual examination capability. The result is a more patient-friendly experience, eliminating the need for physical hospital visits. The metaverse is also proposed for virtual physiotherapy sessions using haptic sensors, aiming to enhance the comfort of treatments for paralysed patients. The potential for remote healthcare services can be explored, with virtual clinics facilitating remote diagnosis, monitoring, and follow-up appointments. This not only improves convenience but also addresses the challenges associated with in-person hospital visits.',\n",
              " 'In the mental health realm, the use of mindfulness apps and virtual reality experiences can be leveraged to alleviate stress and anxiety. Additionally, the metaverse can be instrumental in providing exposure therapy for individuals with phobias, fostering resilience and personal growth. Other applications include real-time patient monitoring within virtual environments, immersive educational experiences for healthcare professionals, and the use of the metaverse for visualising complex health data.',\n",
              " 'In conclusion, this is a very vast topic of study and if implemented, it can prove to be a technological breakthrough for centuries to come. This paper contributes a robust framework for the integration of the metaverse and healthcare. From foundational',\n",
              " 'network development to innovative applications, the proposed methodologies offer a roadmap for realising the transformative potential of this union, promising advancements in medical services and improved well-being for individuals. Research can be extended, metaverse applications can be explored and healthcare in metaverse can soon be a reality.',\n",
              " 'The integration of the metaverse into healthcare represents an ambitious and transformative vision, offering unparalleled opportunities to enhance medical services, improve patient experiences, and revolutionize the delivery of care. This paper provides a forward-looking perspective on how the metaverse could shape the future of healthcare, emphasizing its potential to address existing challenges while introducing groundbreaking innovations. By prioritizing foundational requirements, such as a fast, secure, and reliable network, and focusing on making metaverse technologies affordable and accessible, this paper outlines a comprehensive framework for the development of virtual healthcare systems. The proposals aim not only to improve the efficiency and reach of medical services but also to redefine the way patients and healthcare providers interact.',\n",
              " \"One of the primary contributions of this paper is its emphasis on the critical need for a fast, secure, and reliable network infrastructure to support the metaverse's operations. The metaverse relies on immersive virtual environments and real-time data exchange, requiring low-latency and high-speed connectivity to function effectively. This is especially important for healthcare applications, where precision, timeliness, and reliability are paramount. Virtual consultations, remote surgeries, and diagnostic procedures within the metaverse all demand robust network capabilities to ensure uninterrupted and accurate delivery of services. Investing in next-generation internet technologies, such as 5G and 6G networks, as well as satellite-based systems, is essential to create the digital backbone needed to support metaverse-driven healthcare. Additionally, expanding access to high-speed internet in underserved and remote areas can bridge digital divides and ensure that virtual healthcare is accessible to all, regardless of geographical location.\",\n",
              " 'Affordability of metaverse equipment is another critical focus of this paper, as the high cost of VR and AR devices, haptic sensors, and supporting technologies currently limits their widespread adoption. Making these tools accessible to a broader audience is essential for democratizing the benefits of virtual healthcare and ensuring inclusivity. The paper advocates for collaborative efforts between governments, private companies, and healthcare organizations to reduce costs through subsidies, grants, and advancements in manufacturing processes. Furthermore, the development of lightweight, cost-effective, and user-friendly devices can lower entry barriers for both healthcare providers and patients. Alternative solutions, such as cloud-based platforms and mobile-compatible interfaces, can also play a pivotal role in extending the reach of metaverse healthcare to populations with limited resources.',\n",
              " \"The introduction of a predictive model for early disease detection and timely treatment represents a significant innovation with the potential to transform healthcare outcomes. This model leverages the metaverse's capabilities to monitor patient health in real time, analyze data using AI and machine learning algorithms, and provide early warnings of potential health issues. By enabling early diagnosis and intervention, this predictive approach can reduce mortality rates and improve the overall quality of care. For\",\n",
              " \"example, the model can be used to identify subtle changes in a patient’s health that may indicate the onset of chronic conditions, allowing for proactive management and treatment. The integration of wearable health-monitoring devices and virtual consultations further enhances this model's effectiveness, offering a holistic approach to preventive care.\",\n",
              " 'Immersive simulation environments for medical training are another key innovation proposed in this paper. By utilizing the metaverse to create realistic and interactive virtual training scenarios, healthcare professionals can practice complex procedures and refine their skills in a risk-free setting. These simulations can replicate high-stakes situations, such as emergency surgeries or critical care interventions, enabling practitioners to build confidence and competence. Additionally, virtual training environments can facilitate collaborative learning, allowing medical teams from different parts of the world to work together and share expertise. The potential for these simulations to improve surgical success rates and enhance patient outcomes underscores their value as a transformative tool for medical education and training.',\n",
              " 'Virtual consultations emerge as a particularly valuable application of the metaverse, especially for elderly and paralyzed patients. Unlike traditional video calls, which often have limitations in terms of interaction and assessment, virtual consultations within the metaverse leverage augmented and virtual reality technologies to provide a more comprehensive examination experience. Healthcare providers can use technologies to conduct detailed assessments, monitor patients’ physical conditions, and offer personalized treatment recommendations—all without requiring patients to visit a hospital. This innovation not only improves convenience but also addresses mobility challenges faced by vulnerable populations, making healthcare more patient- centric and accessible. these',\n",
              " 'In addition to consultations, the metaverse offers exciting possibilities for virtual physiotherapy sessions, particularly for patients with paralysis or mobility impairments. By incorporating haptic sensors and feedback mechanisms, these sessions can simulate real-world physical therapy exercises, enabling patients to engage in effective rehabilitation from the comfort of their homes. This approach has the potential to make physiotherapy more convenient, comfortable, and tailored to individual needs, fostering better recovery outcomes.',\n",
              " \"The metaverse's potential applications in mental health care further highlight its versatility and transformative impact. Virtual reality experiences and mindfulness apps within the metaverse can provide immersive therapies for stress reduction, anxiety management, and emotional well-being. Exposure therapy, a proven technique for addressing phobias and PTSD, can be enhanced through the metaverse by creating safe and controlled virtual environments where patients can gradually confront their fears. These innovations not only improve access to mental health services but also offer personalized and engaging treatment options that promote resilience and personal growth.\",\n",
              " 'Other proposed applications of the metaverse in healthcare include real-time patient monitoring within virtual environments, immersive educational experiences for healthcare professionals, and the use of advanced visualization tools to interpret complex health data. For example, clinicians can utilize 3D models and simulations in',\n",
              " 'the metaverse to better understand patient anatomy, plan surgeries, and communicate treatment options to patients. These capabilities enhance the precision and effectiveness of medical interventions, ultimately improving patient outcomes.',\n",
              " 'The potential impact of integrating the metaverse into healthcare extends far beyond individual innovations, representing a paradigm shift in how medical services are delivered and experienced. By addressing foundational requirements, such as network infrastructure and affordability, and exploring a wide range of applications, this paper outlines a robust framework for realizing the transformative potential of this union. The proposed methodologies offer a roadmap for advancing medical services, improving accessibility, and enhancing patient well-being on a global scale.',\n",
              " 'As research and development in this field continue, new opportunities for innovation and impact will emerge, further expanding the possibilities for metaverse-driven healthcare. The integration of the metaverse into healthcare practices has the potential to become a technological breakthrough of the century, shaping the future of medicine for generations to come. Through continued exploration and collaboration, the vision of a comprehensive and inclusive metaverse healthcare ecosystem can become a reality, delivering unparalleled benefits to society and redefining the boundaries of what is possible in modern medicine.',\n",
              " 'The integration of the metaverse into healthcare holds the potential for groundbreaking advancements, with benefits that could impact millions. While there are challenges to building this immersive virtual environment, the rewards for medical services and patient well-being are immense. This paper outlines a practical roadmap for realizing these benefits, beginning with establishing a reliable network infrastructure to support seamless connectivity and data exchange in the metaverse. Ensuring the affordability of metaverse technologies is essential for enabling broad adoption and reaching diverse user populations.',\n",
              " 'The paper’s proposed predictive model for early diagnosis represents a major opportunity to improve healthcare outcomes by saving lives through early intervention. Additionally, realistic training simulations within the metaverse could equip healthcare professionals with advanced skills, enhancing treatment accuracy and patient care. Ultimately, these contributions form a robust foundation for integrating the metaverse with healthcare, opening a new era in medical innovation and improved patient experiences. Continued research and development can further explore these applications, bringing healthcare in the metaverse closer to reality.',\n",
              " 'The potential impact of the metaverse on healthcare is substantial, and its application has the capacity to touch the lives of millions. While developing this virtual realm may pose challenges, the rewards in transforming our way of life are significant. This paper outlines practical steps to kickstart this transformative journey.',\n",
              " 'To begin, establishing a swift, secure, and reliable network is foundational. A robust network forms the backbone, ensuring seamless connectivity and data exchange within the metaverse, a crucial aspect for effective healthcare applications. Affordability of metaverse equipment is another key consideration. Making these tools accessible to a broader population enhances their adoption, democratising the benefits of virtual healthcare experiences. This step is pivotal in ensuring inclusivity and reaching a diverse range of users. The paper introduces a predictive model designed to decrease mortality rates through early disease detection and timely treatment. This approach utilises the metaverse to enhance diagnostic capabilities, potentially revolutionising healthcare outcomes and saving lives. Furthermore, the paper suggests immersive practice environments for medical procedures. By providing a platform for realistic simulations, healthcare practitioners can refine their skills, potentially leading to increased success rates in surgeries. This not only benefits medical professionals but also contributes to better patient outcomes. These practical methodologies offer a feasible path forward, addressing challenges and providing insights into bridging gaps in the development of the metaverse in healthcare. The potential for positive, long- lasting effects on society is evident. As we embark on this journey, it is clear that the healthcare sector holds immense promise for technological breakthroughs that could shape the future for generations to come. The opportunities for innovation and positive impact in this field are vast, making it a focal point for future advancements.',\n",
              " 'The integration of the metaverse into healthcare holds unparalleled potential for transforming the way medical services are delivered, bringing groundbreaking advancements that could positively impact millions of lives worldwide. By blending immersive virtual environments with cutting-edge technologies, the metaverse offers opportunities to revolutionize patient care, enhance medical training, and address persistent challenges in healthcare accessibility and efficiency. While building this virtual realm involves numerous technical, financial, and logistical hurdles, the rewards for medical services, patient well-being, and societal health are immense. This paper outlines a practical roadmap for harnessing these benefits, focusing on key foundational requirements, innovative solutions, and strategies to address barriers implementation. to',\n",
              " 'To begin, the establishment of a swift, secure, and reliable network infrastructure is paramount. The metaverse is a highly data-intensive environment, requiring seamless connectivity, low-latency interactions, and real-time data exchange to function effectively. Healthcare applications within the metaverse, such as virtual consultations, remote surgeries, and AI-assisted diagnostics, demand an exceptionally robust digital backbone. Without a reliable network, the immersive experience and precision necessary for healthcare solutions cannot be achieved. This foundational requirement highlights the urgent need for substantial investments in global internet infrastructure. Expansion and upgrading of fiber-optic networks, deployment of next-generation 5G and 6G technologies, and the advancement of satellite internet systems are critical steps to ensure that the metaverse is accessible to all. Governments, private sector stakeholders, and technology providers must collaborate to close connectivity gaps, particularly in underserved and rural areas. Achieving this goal not only supports the development of metaverse-driven healthcare but also promotes digital inclusivity, bridging the divide between urban and rural populations in access to advanced medical services.',\n",
              " 'Equally important is addressing the affordability of metaverse technologies to enable broad adoption across diverse user populations. The hardware necessary for accessing and engaging with the metaverse—such as VR headsets, AR devices, haptic feedback systems, and high-performance computing platforms—remains prohibitively expensive for many individuals and healthcare institutions. This cost barrier limits the scalability of metaverse applications in healthcare and restricts their availability to a narrow demographic. For the metaverse to truly democratize healthcare, its technologies must be made affordable and accessible. Governments and international organizations can play a crucial role by offering subsidies, grants, or tax incentives to healthcare providers investing in metaverse technologies. Simultaneously, technology companies must prioritize innovation aimed at cost reduction, such as developing lightweight, portable, and energy-efficient devices that maintain high performance while being economically viable. The use of scalable manufacturing processes and alternative materials can further contribute to lowering production costs. In parallel, developing software platforms that require minimal hardware specifications, such as cloud-based solutions or mobile-compatible interfaces, can extend the reach of metaverse healthcare to populations with limited resources.',\n",
              " 'A particularly transformative aspect of the metaverse in healthcare is its potential to enhance early diagnosis and intervention through predictive models. The paper introduces a predictive model designed to significantly reduce mortality rates by leveraging the metaverse to detect diseases in their early stages and enable timely treatment. This model integrates advanced artificial intelligence (AI) algorithms, machine learning techniques, and comprehensive health data analytics to identify subtle patterns and warning signs of illnesses. By doing so, the metaverse could serve as a proactive healthcare platform, where patients are routinely monitored in immersive environments and alerted to potential health concerns before they escalate. This innovation has the power to revolutionize diagnostic capabilities, shifting the focus from reactive to preventive care and saving countless lives. However, realizing this vision requires significant advancements in AI training, data standardization, and privacy safeguards. Ensuring that predictive models are accurate, unbiased, and capable of generalizing across diverse populations is critical. Furthermore, the integration of wearable health-monitoring devices and real-time data feeds into the metaverse can provide continuous insights into patients’ health, enhancing the effectiveness of predictive diagnostics.',\n",
              " 'Another vital contribution of the metaverse to healthcare lies in its ability to provide immersive and realistic training environments for medical professionals. By leveraging the metaverse for advanced training simulations, healthcare practitioners can refine their skills and gain hands-on experience in a safe and controlled virtual setting. These simulations can replicate complex surgical procedures, emergency response scenarios, and intricate diagnostic processes, allowing practitioners to practice repeatedly and gain confidence before performing on actual patients. The benefits of such training extend beyond skill enhancement; they contribute to increased success rates in surgeries and other medical interventions, ultimately improving patient outcomes. Moreover, the metaverse offers opportunities for collaborative training, where medical teams from different parts of the world can convene in virtual environments to share expertise and learn from one another. This global exchange of knowledge fosters innovation, raises the standard of medical education, and ensures that healthcare professionals remain at the forefront of their fields. To maximize the potential of metaverse-based training,',\n",
              " 'investments in high-fidelity simulation technologies, virtual anatomy models, and haptic feedback systems are essential. Additionally, partnerships between medical institutions, technology developers, and accreditation bodies can establish standardized curricula and certifications for virtual training programs, ensuring their widespread adoption and credibility.',\n",
              " 'The paper also emphasizes the importance of bridging the gaps in existing metaverse healthcare applications to create a comprehensive, integrated ecosystem. Practical methodologies outlined in the paper provide a feasible path forward, addressing challenges such as interoperability, user experience, and data security. Interoperability is crucial for enabling seamless interaction between different metaverse platforms, healthcare systems, and devices. Achieving this requires the development of common standards, protocols, and frameworks that facilitate compatibility and data exchange across diverse technologies. Enhancing user experience is another critical consideration, as the success of metaverse healthcare depends on its ability to engage and support patients in an intuitive and meaningful way. Designing user-friendly interfaces, incorporating accessibility features, and personalizing interactions can ensure that the metaverse caters to the needs of all users, including those with disabilities or limited technological literacy. Data security and privacy are paramount in the metaverse, particularly in the context of healthcare, where sensitive patient information is involved. Robust encryption, secure authentication mechanisms, and compliance with international data protection regulations are essential to build trust and safeguard users’ rights.',\n",
              " 'As we embark on this transformative journey, the potential for positive, long-lasting effects on society becomes increasingly evident. The integration of the metaverse into healthcare not only addresses existing gaps in medical services but also opens new avenues for innovation and impact. From early diagnostics and preventive care to advanced training and global collaboration, the opportunities for technological breakthroughs in this field are vast. Continued research and development will play a crucial role in further exploring these applications, refining their effectiveness, and bringing them closer to reality. By fostering collaboration among stakeholders, prioritizing inclusivity, and addressing critical challenges, the metaverse has the potential to reshape the future of healthcare, improving outcomes and enhancing the quality of life for generations to come. This vision represents a new era in medical innovation, where the boundaries of possibility are expanded, and the promise of equitable, efficient, and patient-centered care is realized.',\n",
              " '10. Ganapathy, K. (2022) ‘Metaverse and healthcare: a clinician’s perspective’.',\n",
              " 'import sys # Initialize Pygame pygame.init() # Screen settings screen_width, screen_height = 800, 600 screen = pygame.display.set_mode((screen_width, screen_height)) pygame.display.set_caption(\"Healthcare Metaverse Simulation\")',\n",
              " '# Colors',\n",
              " 'white = (255, 255, 255) blue = (50, 50, 255) green = (0, 255, 0)',\n",
              " '# Entity positions doctor_position = (150, 200) monitor_position = (500, 300) font = pygame.font.Font(None, 36)',\n",
              " '# Main loop running = True while running: screen.fill(white) # Fill background with white',\n",
              " 'for event in pygame.event.get(): if event.type == pygame.QUIT: pygame.quit() sys.exit()',\n",
              " '# Display healthcare entities',\n",
              " 'pygame.draw.rect(screen, blue, (*doctor_position, 100, 150)) # Doctor as blue rectangle',\n",
              " 'pygame.draw.rect(screen, green, (*monitor_position, 120, 80)) # Health monitor as green rectangle',\n",
              " 'doctor_text = font.render(\"Virtual Doctor\", True, (0, 0, 0)) monitor_text = font.render(\"Health Monitor\", True, (0, 0, 0)) screen.blit(doctor_text, (doctor_position[0], doctor_position[1] - 30)) screen.blit(monitor_text, (monitor_position[0], monitor_position[1] - 30))',\n",
              " 'instruction_text = font.render(\"Welcome to the Virtual Healthcare Room\", True, (0, 0, 0)) screen.blit(instruction_text, (screen_width // 4, 50))']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=[]\n",
        "for element in raw_pdf_element:\n",
        "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "    img.append(str(element))"
      ],
      "metadata": {
        "id": "E3fNjWvzadx5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J-tlzzSfavR7",
        "outputId": "029cb95f-9537-449c-b46c-0b66b87cb8ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iii  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tab=[]\n",
        "for element in raw_pdf_element:\n",
        "  if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "    tab.append(str(element))"
      ],
      "metadata": {
        "id": "Cxeqit5obNWd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tab[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "4QBekouUbTLU",
        "outputId": "d80491a3-75ea-41ee-a218-5caf76164ac0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Contents Abstract INTRODUCTION 1.1 Background 1.2 Motivations 1.3 Scope of the Project PROJECT DESCRIPTION AND GOALS 2.1 Literature Review 2.2 Research Gap 2.3 Objectives 2.4 Problem Statement 2.5 Project Plan TECHNICAL SPECIFICATION 3.1 Requirements 3.1.1 Functional 3.1.2 Non-Functional 3.2 Feasibility Study 3.2.1 Technical Feasibility 3.2.2 Economic Feasibility 3.2.2 Social Feasibility 3.3 System Specification 3.3.1 Hardware Specification 3.3.2 Software Specification DESIGN APPROACH AND DETAILS 4.1 System Architecture 4.2 Design 4.2.1 Data Flow Diagram 4.2.2 Use Case Diagram METHODOLOGY AND TESTING Methodology 1 Methodology 2 Methodology 3 Methodology 4 11 12 12 12 13 14 14 15 16 16 17 18 18 18 18 18 18 18 19 19 19 20 20 20 21 22 25 26 27 28'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}